{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Research Software Good Practice","text":"<p> Research software development differs from standard software development in some core ways. These guides aim to provide a set of good practices that can be applied to research software development to ensure that the software is of high quality, maintainable, reusable and reproducible.</p>"},{"location":"#research-good-practice-initiatives","title":"Research Good-Practice Initiatives","text":"<p>There are many initiatives in the research software community to develop training and standards. One of these that is well established is The Turing Way, a published gude to reproducible, ethical and collaborative data science. (The Turing Way 2025).</p>"},{"location":"#icr-internal-training","title":"ICR Internal Training","text":"<p>The ICR runs some courses on research software development best practices, covering training through the carpentries organisation, usually in-person and can be found on the ICR training website (search carpentry). </p>"},{"location":"#webinar-series-good-practice-in-research-software","title":"Webinar Series: Good-Practice in Research Software","text":"<p>This is a series of webinars run by the ICR Research Software Engineering team, covering good practices in research software development. The webinars are recorded and available on (link to come soon). The overview page is here, and in summary it covers: - Monday: Bash and VScode - Tuesday: Git and GitHub - Wednesday: Python projects - Thursday: R projects - Friday: Conda environments  </p>"},{"location":"#webinar-series-vibe-coding","title":"Webinar Series: Vibe-Coding","text":"<p>Coming soon in February 2026  </p>"},{"location":"#challenges-in-research-software","title":"Challenges in Research Software","text":"<p>Research software development differs from standard software development in some core ways. This resource aims to help with good practices that can be applied to research software development to ensure that the software is of high quality, maintainable, reusable and reproducible.</p> <p>Key differences include:</p> <ul> <li> <p>Research software is often developed in a more exploratory manner with no known ground truth. This means that the requirements of the software and the test outcomes are not always clear at the outset. The software and test environment may need to be adapted as the research progresses.</p> </li> <li> <p>Research software is often developed by researchers who may not have a background in software development. This can lead to software that is not well-structured, poorly documented, and difficult to maintain.</p> </li> <li> <p>Research software is often developed as a means to an end, rather than as an end in itself. This can lead to software that is not well-tested, and that may not be suitable for reuse by others.</p> </li> <li> <p>Research software is often developed in a time-constrained environment, with researchers under pressure to produce results quickly. This can lead to software that is not well-designed, and that may not be scalable or maintainable in the long term.</p> </li> <li> <p>Research software is often developed in a collaborative environment, with multiple researchers working on the same codebase. This can lead to issues with code quality, consistency, and maintainability.</p> </li> <li> <p>A demonstration of correctness may be required for a research paper. This is an output of the software that differs from traditional software (where the software itself is the output).</p> </li> </ul> <p>Given these challenges, it can be difficult to apply standard software development practices to research software.</p> <p>However, there are a number of good practices that can be applied to research software development to ensure that the software is of high quality, maintainable, and reusable. These practices include: - Writing clean, readable code - Using version control - Documenting the software - Writing tests - Using continuous integration - Using environments - Using a code review process</p>"},{"location":"#references","title":"References","text":"<ul> <li>The Turing Way Community. (2022). The Turing Way: A handbook for reproducible, ethical and collaborative research (1.0.2). Zenodo. DOI The Turing Way Community (2025). </li> </ul>"},{"location":"about/","title":"Research Software Good Practice","text":"<p>Research software development differs from standard software development in some core ways. This guide aims to provide a set of good practices that can be applied to research software development to ensure that the software is of high quality, maintainable, reusable and importantly - reproducible.</p> <p>Key differences include:</p> <ul> <li> <p>Research software is often developed in a more exploratory manner with no known ground truth. This means that the requirements of the software and the test outcomes are not always clear at the outset. The software and test environment may need to be adapted as the research progresses.</p> </li> <li> <p>Research software is often developed by researchers who may not have a background in software development. This can lead to software that is not well-structured, poorly documented, and difficult to maintain.</p> </li> <li> <p>Research software is often developed as a means to an end, rather than as an end in itself. This can lead to software that is not well-tested, and that may not be suitable for reuse by others.</p> </li> <li> <p>Research software is often developed in a time-constrained environment, with researchers under pressure to produce results quickly. This can lead to software that is not well-designed, and that may not be scalable or maintainable in the long term.</p> </li> <li> <p>Research software is often developed in a collaborative environment, with multiple researchers working on the same codebase. This can lead to issues with code quality, consistency, and maintainability.</p> </li> <li> <p>A demonstration of correctness is often required for research software for a research paper. This is an ouput of the software that differs from traditional sofwtare (where the software itself is the output).</p> </li> </ul> <p>Given these challenges, it can be difficult to apply standard software development practices to research software.</p> <p>However, there are a number of good practices that can be applied to research software development to ensure that the software is of high quality, maintainable, and reusable. These practices include: - Using version control - Writing clean, readable code - Writing tests - Documenting the software - Using continuous integration - Using a package manager - Using a code review process</p> <p>This guide provides an overview of each of these practices, as well as links to further resources that can help you to implement them in your own research software projects.</p> <p>As a self-referential example, this guide is written in markdown and rendered using mkdocs. The build process is autoamtically kicked off with github actions when a change is pulled into the main branch.  The source code for this guide is available on GitHub at ICR-RSE-Group/good-practice</p>"},{"location":"examples/streamlit1/","title":"Making this application a streamlit app","text":"<ol> <li> <p>Make basic struct of <pre><code>    - requirements.txt\n    - citation.cff\n    - app dir\n    - app/static dir\n</code></pre></p> </li> <li> <p>Add a basic streamlit app to app dir</p> </li> <li> <p>app/home.py <pre><code>import streamlit as st\nst.set_page_config(\n        page_title=\"good-practice\",\n        page_icon=\"app/static/good.png\",\n        layout=\"wide\",\n    )\nst.header(\"Research Software Good Practice\")\n</code></pre></p> </li> <li> <p>Put an icon in the static dir</p> </li> <li> <p>app/static/good.png This is simply good practice to check paths and file names and looks better. Streamlit doesn't require the ico format.</p> </li> <li> <p>Make a virtual environment <pre><code>python3 -m venv venv\nsource venv/bin/activate # linux\nvenv\\Scripts\\activate # windows\n</code></pre></p> </li> <li> <p>Install the requirements <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Run the streamlit app <pre><code>streamlit run app/home.py\n</code></pre></p> </li> <li> <p>Find a very rough example to work with and add it to the streamlit app</p> </li> <li>app/home.py Make sure to track the references for the code snippets. https://stackoverflow.com/questions/25148462/open-a-url-by-clicking-a-data-point-in-plotly</li> </ol>"},{"location":"examples/streamlit1/#additional-imports-compared-with-above-example","title":"Additional imports compared with above example:","text":"<p>import math import plotly.express as px import pandas as pd</p> <p>df = px.data.gapminder().query(\"year==2007 and continent=='Asia'\") fig = px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", color=\"lifeExp\", \\                  size=\"pop\", log_x=True, size_max=60)</p> <p>fig.update_layout(     height=800,width=1200,     title_text='GDP and Life Expectancy (Asia, 2007)' ) for idx in df.index:     url=\"\"+df['country'][idx]+\"\"     fig.add_annotation(dict(x=math.log10(df['gdpPercap'][idx]),                             y=df['lifeExp'][idx],                             showarrow=False,                             text=url,                             xanchor='auto',                             yanchor='auto')) fig.show()</p> <ol> <li> <p>Design a basic dataframe to use for a similar example It needs</p> <ul> <li>a name, which we can use to make the url, </li> <li>a level, eg beginners etc</li> <li>a position on the chart</li> <li>a type for the hue <pre><code>resource,level,position,kind\ngood-practice-intro,0,0,doc\npython-lib-example\",1,1.1,follow-along\npython-streamlit-example,1,1.2,follow-along\nr-lib-example,1,2.1,follow-along\nr-shiny-example,1,2.2,follow-along\nvscode-intro\",0,3,tools\npython-for-hpc,3,1.3,doc\n</code></pre></li> </ul> </li> <li> <p>Add this example to the streamlit app</p> </li> <li> <p>Add a basic test to the app dir</p> </li> <li> <p>Move the plt to a page with pages</p> </li> <li> <p>Update necessary tests</p> </li> <li> <p>Set up the branch safety in guthub</p> </li> </ol> <p>Deployment option 1 14. Create a dockerfile and build the docker image</p> <ol> <li> <p>Test the docker image</p> </li> <li> <p>Add the github actions to build the docker image</p> </li> <li> <p>Deploy the docker image to ICR</p> </li> </ol> <p>Deployment option 2 14. Create a  streamlit account</p> <ol> <li> <p>Deploy to streamlit</p> </li> <li> <p>Add a basic test to app dir</p> </li> <li>Add a basic setup.py to app dir</li> <li>Add a basic README.md to app dir</li> <li>Add a basic LICENSE to app dir</li> <li>Add a basic .gitignore to app dir</li> <li>Add a basic .dockerignore to app dir</li> <li>Add a basic Dockerfile to app dir</li> <li>Add a basic .github/workflows to app dir</li> </ol> <p>::: warning here be dragons :::</p> <p>[!EXAMPLE] this is an example</p> <p>[!NOTE] This is a note</p> <p>[!NOTE] Beside results initiated by a command (synchronous) you can get asynchronous results initiated by rule trigger, telemetry event, commands from other source or changed device values.   Simply put, other messages may precede messages published as a result of your commands.</p> <p>[!EXAMPLE] A <code>tele/%topic%/STATUS</code> message (sent every 300 seconds by default) may appear exactly after you issue <code>Power off</code> command and before you receive <code>stat/%topic%/RESULT = {\"POWER\":\"OFF\"}</code> message.</p> <p>https://squidfunk.github.io/mkdocs-material/reference/diagrams/ https://mermaid.js.org/syntax/gitgraph.html</p> <pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];\n  click B \"https://www.github.com\" \"This is a tooltip for a link\"\n  style A fill:#f9f,stroke:#333,stroke-width:4px\n  style B fill:#bbf,stroke:#f66,stroke-width:2px,color:#fff,stroke-dasharray: 5 5</code></pre>"},{"location":"examples/streamlit1/#a-github-style-chart","title":"A github style chart","text":"<pre><code>gitGraph\n    commit id: \"1\"\n    commit id: \"2\"\n    branch nice_feature\n    checkout nice_feature\n    commit id: \"3\"\n    checkout main\n    commit id: \"4\"\n    checkout nice_feature\n    branch very_nice_feature\n    checkout very_nice_feature\n    commit id: \"5\"\n    checkout main\n    commit id: \"6\"\n    checkout nice_feature\n    commit id: \"7\"\n    checkout main\n    merge nice_feature id: \"customID\" tag: \"customTag\" type: REVERSE\n    checkout very_nice_feature\n    commit id: \"8\"\n    checkout main\n    commit id: \"9\"</code></pre>"},{"location":"good/friday/","title":"Friday Session: Containerization &amp; Environment Management","text":"<p>Duration: 60 minutes | Format: Interactive demonstration and hands-on practice</p>"},{"location":"good/friday/#summary","title":"Summary","text":"<p>Friday's session focuses on containerization and advanced environment management for reproducible research. You'll learn to use Docker for creating portable, reproducible environments and explore conda for package management. We'll demonstrate a foundation for scalable, reproducible research workflows.</p>"},{"location":"good/friday/#what-we-cover","title":"What We Cover","text":""},{"location":"good/friday/#docker-fundamentals","title":"Docker Fundamentals","text":"<ul> <li>Installing and configuring Docker</li> <li>Basic Docker commands and workflow</li> <li>Creating simple Dockerfiles for research projects</li> </ul>"},{"location":"good/friday/#conda-environment-management","title":"Conda Environment Management","text":"<ul> <li>Installing Anaconda/Miniconda</li> <li>Creating and managing conda environments</li> <li>Using environment.yml files for reproducibility</li> <li>Comparing conda vs pip for package management</li> </ul>"},{"location":"good/friday/#practical-applications","title":"Practical Applications","text":"<ul> <li>Containerizing a simple analysis pipeline</li> <li>Sharing reproducible environments with colleagues</li> <li>Converting docker to singularity for HPC</li> </ul>"},{"location":"good/friday/#key-takeaways","title":"Key Takeaways","text":"<p>By the end of this session, you'll be able to:</p> <ul> <li>Create Docker containers for your research projects to ensure reproducibility across different systems</li> <li>Manage Python environments using conda to avoid dependency conflicts</li> <li>Share reproducible environments with collaborators using container images and environment files</li> <li>Understand when to use containers vs virtual environments for different research scenarios</li> <li>Apply containerization to make your research more portable and reproducible</li> </ul>"},{"location":"good/friday/#videos-of-session","title":"Videos of session","text":"<ul> <li>Section 1/3 19.01  </li> <li>Section 2/3 19.19  </li> <li>Section 3/3 13.08  </li> </ul>"},{"location":"good/friday/#additional-resources","title":"Additional Resources","text":"<ul> <li>Docker for Data Science Tutorial</li> <li>Conda User Guide</li> <li>The Turing Way: Reproducible Environments</li> <li>Docker Best Practices for Research</li> <li>Link to repo: github.com/ICR-SC/gp-01-biomarkers </li> </ul>"},{"location":"good/friday/#cheat-sheet","title":"Cheat Sheet","text":""},{"location":"good/friday/#conda-commands-used","title":"Conda Commands Used:","text":"<pre><code># Create Python environment\nconda create -n good-python python=3.13 pandas matplotlib pytest -y\nconda activate good-python\nconda list\n\n# Create R environment  \nconda create -n good-r r-base=4.3 r-tidyverse r-ggplot2 r-testthat -y\nconda activate good-r\n\n# Export environment\nconda env export &gt; environment.yml\n\n# Export platform indeppendedn\nconda env export --no-build &gt; environment.yml\n\n# Run scripts\npython src/python/analysis.py\nRscript src/R/analysis.R\n</code></pre>"},{"location":"good/friday/#docker-commands-used","title":"Docker Commands Used:","text":"<pre><code># Build Docker images\ndocker build -f docker/Dockerfile.python -t good-python .\ndocker build -f docker/Dockerfile.r -t good-r .\ndocker build -f docker/Dockerfile.conda -t good-conda .\n# Look inside the docker image and navigate with bash\ndocker run -it good-python /bin/bash\n# Run Docker containers\ndocker run --rm -v $(pwd)/data:/app/data -v $(pwd)/results:/app/results good-python\ndocker run --rm -v $(pwd)/data:/app/data -v $(pwd)/results:/app/results good-r\ndocker run --rm -v $(pwd)/data:/app/data -v $(pwd)/results:/app/results good-conda python analysis.py\ndocker run --rm -v $(pwd)/data:/app/data -v $(pwd)/results:/app/results good-conda Rscript analysis.R\n</code></pre>"},{"location":"good/friday/#dockerfile-examples-created","title":"Dockerfile Examples Created:","text":"<pre><code># Python Dockerfile\nFROM python:3.13-slim\nWORKDIR /app\nRUN pip install pandas matplotlib pytest\nCOPY src/python/analysis.py ./analysis.py\nCMD [\"python\", \"analysis.py\"]\n\n# R Dockerfile  \nFROM rocker/r-base:4.3.1\nWORKDIR /app\nCOPY src/R/analysis.R ./analysis.R\nCOPY data/raw ./data/raw\nRUN R -e \"install.packages(c('tidyverse', 'ggplot2', 'testthat'), repos='https://cloud.r-project.org')\"\nCMD [\"Rscript\", \"analysis.R\"]\n\n# Conda Dockerfile\nFROM continuumio/miniconda3:latest\nWORKDIR /app\nCOPY environment.yml .\nCOPY src/python/analysis.py ./analysis.py\nCOPY src/R/analysis.R ./analysis.R\nCOPY data/raw ./data/raw\nRUN conda env create -f environment.yml\nSHELL [\"conda\", \"run\", \"-n\", \"good-env\", \"/bin/bash\", \"-c\"]\nENTRYPOINT [\"conda\", \"run\", \"-n\", \"good-env\"]\nCMD [\"python\", \"analysis.py\"]\n</code></pre>"},{"location":"good/friday/#singularity-commands-used","title":"Singularity Commands used","text":"<pre><code># Build Docker image\ndocker build -f Dockerfile.conda -t good-conda .\nsingularity build good-conda.sif docker-daemon://good-conda:latest\n#or \ndocker save good-conda:latest -o good-conda.tar\nsingularity build good-conda.sif docker-archive://good-conda.tar\n\n# (Copy files and data to alma, eg /data/scratch/etc...)\n## Run the Python script\nsingularity exec --bind data:/app/data,results:/app/results good-conda.sif bash -c \"source /opt/conda/etc/profile.d/conda.sh &amp;&amp; conda run -n good-env python /app/analysis.py\"\n\n## Run the R script\nsingularity exec --bind data:/app/data,results:/app/results good-conda.sif bash -c \"source /opt/conda/etc/profile.d/conda.sh &amp;&amp; conda run -n good-env Rscript /app/analysis.R\"\n</code></pre>"},{"location":"good/monday/","title":"Monday Overview: Good-Practices in Research Coding","text":"<p>Goal: Learn how to use the command line, log into the Alma HPC cluster, and set up a sensible, reproducible project folder for your research.</p>"},{"location":"good/monday/#what-we-cover","title":"What We Cover","text":"<ul> <li>How to open and use the command line (Windows, Mac, Linux)</li> <li>Basic navigation and file/folder creation: <code>ls</code>, <code>cd</code>, <code>pwd</code>, <code>mkdir</code>, <code>touch</code></li> <li>Editing files with <code>nano</code> and viewing them with <code>cat</code></li> <li>Logging into the Alma HPC cluster using SSH</li> <li>Understanding login nodes vs compute nodes on Alma</li> <li>Running interactive jobs with <code>srun</code></li> <li>Creating a simple, organized project folder for your research</li> <li>Opening and using VSCode for coding and project management</li> </ul>"},{"location":"good/monday/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>The command line is a powerful tool for navigating, creating, and managing files and folders.</li> <li>Use <code>.gitignore</code> to keep sensitive or unnecessary files out of version control.</li> <li>Organize your project folders for clarity and reproducibility.</li> <li>Use VSCode\u2019s built-in terminal and editor to streamline your workflow.</li> <li>Practice makes perfect\u2014try these commands on your own!</li> </ul>"},{"location":"good/monday/#videos-of-session","title":"Videos of session","text":"<ul> <li>Section 1/3 18.07  </li> <li>Section 2/3 19.02  </li> <li>Section 3/3 24.12  </li> </ul>"},{"location":"good/monday/#session-cheat-sheet-monday","title":"Session Cheat Sheet: Monday","text":""},{"location":"good/monday/#basic-command-line","title":"Basic Command Line","text":"<pre><code># Where am I?\npwd\n\n# List files and folders\nls\n\n# Make a new folder for practice\nmkdir test_folder\n\n# Go into it\ncd test_folder\n\n# Make a file\ntouch example.txt\n\n# See the file\nls\n</code></pre>"},{"location":"good/monday/#editing-and-viewing-files","title":"Editing and Viewing Files","text":"<pre><code>nano example.txt\n# (Type your text, then Ctrl+O to save, Ctrl+X to exit)\n\ncat example.txt\n</code></pre>"},{"location":"good/monday/#more-advanced-command-line","title":"More Advanced Command Line","text":"<pre><code># See hidden files\nls -la\n\n# Make several folders at once\nmkdir -p data/{raw,processed}\n\n# Remove a file\nrm example.txt\n\n# Go up a folder\ncd ..\n</code></pre>"},{"location":"good/monday/#logging-into-alma","title":"Logging into Alma","text":"<pre><code>ssh &lt;username&gt;@alma.icr.ac.uk\n</code></pre>"},{"location":"good/monday/#compute-nodes","title":"Compute Nodes","text":"<pre><code>srun --pty -t 12:00:00 --cpus-per-task 1 --mem-per-cpu 4021 --partition interactive bash\nsqueue -u $USER\n</code></pre>"},{"location":"good/monday/#project-folder-and-vscode","title":"Project Folder and VSCode","text":"<pre><code>cd ..\nrm -rf test_folder\nmkdir biomarkers_project\ncd biomarkers_project\ncode .\n</code></pre>"},{"location":"good/monday/#making-a-sensible-project-structure","title":"Making a Sensible Project Structure","text":"<pre><code>mkdir -p data/{raw,processed} src docs results notebooks environment\n</code></pre>"},{"location":"good/monday/#adding-and-running-a-script","title":"Adding and Running a Script","text":"<pre><code>touch process_data.sh\nchmod +x process_data.sh\n./process_data.sh\n</code></pre>"},{"location":"good/monday/#homework","title":"Homework","text":"<ul> <li>Practice basic command line commands</li> <li>Try logging into Alma if you have access</li> <li>Create and organize a simple project folder, and open it in VSCode</li> </ul>"},{"location":"good/monday/#reflection","title":"Reflection","text":"<ul> <li>What did you find easy or challenging about using the command line?</li> <li>Were you able to log into Alma? If not, what issues did you encounter?</li> <li>How does organizing your project folder help your research?</li> </ul>"},{"location":"good/overview/","title":"5-Session Webinar in Coding Good Practices","text":"<p>Reproducible Computational Research Skills for ICR Researchers</p>"},{"location":"good/overview/#course-overview","title":"Course Overview","text":"<p>A practical 5-day course teaching essential coding practices for reproducible research, based on The Turing Way framework. Designed for researchers at all technical levels who use computational methods in their work.</p>"},{"location":"good/overview/#who-might-be-interested","title":"Who might be interested?","text":"<ul> <li>PhD students and postdocs working with data analysis</li> <li>Principal investigators managing computational research projects  </li> <li>Research staff collaborating across computational and clinical teams</li> <li>Anyone writing code for research who wants to improve their practices</li> </ul> <p>No prior programming experience required \u2013 the course accommodates mixed technical backgrounds.</p>"},{"location":"good/overview/#learning-outcomes","title":"Learning Outcomes","text":"<p>By the end of this course, you will be able to:</p> <ul> <li>Log in to Alma for high-performance computing</li> <li>Create standardized project structures for reproducible workflows</li> <li>Use version control (Git) effectively for collaboration and change tracking</li> <li>GitLab and GitHub repositories understand how to access the ICR's own instances</li> <li>Python code in VSCode a simple workflow with testing</li> <li>R in RStudio a simple workflow with testing</li> <li>Manage computational environments using conda and Docker for long-term reproducibility</li> <li>Apply The Turing Way principles for transparent, collaborative, and sustainable research</li> </ul>"},{"location":"good/overview/#course-schedule","title":"Course Schedule","text":"<p>Format: 1 hour live session per day, Monday\u2013Friday + homework exercises Style: Interactive, hands-on learning with practical application to your research</p> Day Topic Live Session Highlights Monday Command Line &amp; VSCode Foundations Project organization, command line, VSCode setup Tuesday Git &amp; Collaboration Workflows Git basics, collaboration, merge conflicts Wednesday Python Development in VSCode Testing, analysis pipeline Thursday R Development in RStudio and VSCode Testing, analysis pipeline Friday Computational Reproducibility Conda/Docker environments, sharing, sustainability"},{"location":"good/overview/#video-playlists","title":"Video Playlists","text":""},{"location":"good/overview/#monday","title":"Monday","text":"<ul> <li>Section 1/3 18.07  </li> <li>Section 2/3 19.02  </li> <li>Section 3/3 24.12  </li> </ul>"},{"location":"good/overview/#tuesday","title":"Tuesday","text":"<ul> <li>Section 1/3 8.45  </li> <li>Section 2/3 27.20  </li> <li>Section 3/3 24.30  </li> </ul>"},{"location":"good/overview/#wednesday","title":"Wednesday","text":"<ul> <li>Section 1/3 21.19  </li> <li>Section 2/3 15.06  </li> <li>Section 3/3 19.43  </li> </ul>"},{"location":"good/overview/#thursday","title":"Thursday","text":"<ul> <li>Section 1/3 15.55   </li> <li>Section 2/3 17.21   </li> <li>Section 3/3 17.15  </li> </ul>"},{"location":"good/overview/#friday","title":"Friday","text":"<ul> <li>Section 1/3 19.01    </li> <li>Section 2/3 19.19  </li> <li>Section 3/3 13.08  </li> </ul>"},{"location":"good/overview/#technical-requirements","title":"Technical Requirements","text":"<ul> <li>Laptop with administrator privileges for software installation</li> <li>ICR network access for GitLab and HPC integration</li> <li>Pre-course setup instructions </li> </ul> <p>All necessary software is free and open-source.</p>"},{"location":"good/overview/#time-commitment","title":"Time Commitment","text":"<ul> <li>Live Sessions: 5 hours total (1 hour per day)</li> <li>Session reviews: 30 mins post session review suggestion</li> <li>Total Course Investment: ~8 hours over one week</li> </ul> <p>Each session builds systematically \u2013 though Wednesday/Thursday are somewhat interchangeable being R and Python.</p>"},{"location":"good/overview/#acknowledgements","title":"Acknowledgements","text":"<p>This training material adapts and builds upon The Turing Way's open-source content under CC-BY 4.0 license. We acknowledge the diverse global community of contributors who have developed these evidence-based practices for reproducible research.</p> <p>More information: https://book.the-turing-way.org/</p>"},{"location":"good/setup/","title":"5-Session Coding Good Practices Course","text":""},{"location":"good/setup/#prerequisites-and-setup-guide","title":"Prerequisites and Setup Guide","text":"<p>Complete these setup steps before the first session to ensure a smooth learning experience. If you have any problems, please contact the RSE team for help!</p>"},{"location":"good/setup/#overview","title":"Overview","text":"<p>This course will teach you coding good practices for reproducible research referencing The Turing Way framework. To participate fully, you'll need several tools installed and accounts configured. Please complete all setup steps below.</p> <p>For any of the elements that you do not have access to, you can go back and do the session again following the recording, or the RSE team will help you in a drop-in session in the RSE office.  </p> <p>The summary of the requirements is broken down for each day, with links to fuller instructions below.</p>"},{"location":"good/setup/#mondays-session","title":"Monday's Session","text":"<ul> <li>Install VSCode</li> <li>Access a terminal</li> <li>Have an HPC Alma account</li> <li>Optionally set up Alma ssh keys</li> <li>Optionally setup remote-ssh for VSCode</li> </ul>"},{"location":"good/setup/#tuesdays-session","title":"Tuesday's Session","text":"<ul> <li>Install VSCode</li> <li>Install and configure Git</li> <li>Install GitHub Desktop (Windows/Mac)</li> <li>Set up (internal) GitLab access</li> <li>Set up GitHub access (institutional account)</li> </ul>"},{"location":"good/setup/#wednesdays-session","title":"Wednesday's Session","text":"<ul> <li>Install VSCode</li> <li>Install Python</li> <li>Install and configure Git</li> <li>Set up GitLab access (SSO)</li> </ul>"},{"location":"good/setup/#thursdays-session","title":"Thursday's Session","text":"<ul> <li>Install VSCode</li> <li>Install and configure Git</li> <li>Set up GitLab access</li> <li>R and RStudio</li> </ul>"},{"location":"good/setup/#fridays-session","title":"Friday's Session","text":"<ul> <li>Install VSCode</li> <li>Install Conda (Anaconda)</li> <li>Install Docker</li> </ul>"},{"location":"good/setup/#software-installation","title":"Software Installation","text":"<p>For all software installations at the ICR it is recommended to check with servicedesk@icr.ac.uk. There has beeen a process of centralising installations for Windows 11 machines, and the installations ought to be available through Company POrtal. Always check this first as when installed here you do not need admin rights. Otherwise you will probably need assistance for any installs. Mac users will need admin rights for most installs but it is changing rapidly so please check. In general the links are given to open source software installs but first check Company Portal and ask servicedesk@icr.ac.uk</p>"},{"location":"good/setup/#install-vscode","title":"Install VSCode","text":""},{"location":"good/setup/#windows","title":"Windows","text":"<p>For Windows The application can be installed from Company Portal. </p>"},{"location":"good/setup/#mac","title":"Mac","text":"<p>For Mac the application can be downloaded and installed from here code.visualstudio.com/Download. Choose the User Installer for your system (Apple Silicon or Intel).</p>"},{"location":"good/setup/#access-a-terminal","title":"Access a terminal","text":""},{"location":"good/setup/#windows_1","title":"Windows","text":"<p>Use PowerShell or Command Prompt. But install WSL2 (Windows Subsystem for Linux) for a better experience. This can be installed from Windows Store: </p> <p>Alternatively you can use GitBash for a linux-like terminal experience. This is also available on company portal. </p>"},{"location":"good/setup/#mac_1","title":"Mac","text":"<p>Use the built-in Terminal application.</p>"},{"location":"good/setup/#have-an-hpc-alma-account","title":"Have an HPC Alma account","text":"<p>Alma Pages on Nexus have information on getting started with Alma, or contact schelpdesk.icr.ac.uk.</p>"},{"location":"good/setup/#set-up-alma-ssh-keys","title":"Set up Alma ssh keys","text":"<p>ALmaCookBook instructions</p>"},{"location":"good/setup/#setup-remote-ssh-for-vscode","title":"Setup remote-ssh for VSCode","text":"<p>code.visualstudio.com/docs/remote/ssh AlmaCookBook link </p>"},{"location":"good/setup/#install-and-configure-git","title":"Install and configure Git","text":""},{"location":"good/setup/#windows_2","title":"Windows","text":"<p>Install Git from the Company Portal: </p>"},{"location":"good/setup/#mac_2","title":"Mac","text":"<p>Use HomeBrew, the mac store, or download from git-scm.com.</p>"},{"location":"good/setup/#install-github-desktop","title":"Install GitHub Desktop","text":""},{"location":"good/setup/#windows_3","title":"Windows","text":"<p>For Windows The application can be installed from Company Portal. </p>"},{"location":"good/setup/#mac_3","title":"Mac","text":"<p>For Mac the application can be downloaded and installed from here desktop.github.com.</p>"},{"location":"good/setup/#set-up-gitlab-access","title":"Set up GitLab access","text":"<p>Internal GitLab is here: git.icr.ac.uk/ - sign on using LDAP and your ICR shortname and password. We will walk through this ssh key setup in the git session: docs.gitlab.com/user/ssh </p>"},{"location":"good/setup/#set-up-github-access","title":"Set up GitHub access","text":"<p>Send an email to schelpdesk.icr.ac.uk to request an institutional GitHub account.  You will receieve an invite to your icr email address. The ICR main GitHub page is: github.com/instituteofcancerresearch - you can also have lab pages set up, contact us to ask for help.  </p>"},{"location":"good/setup/#install-python","title":"Install Python","text":""},{"location":"good/setup/#windows_4","title":"Windows","text":"<p>For Windows The application can be installed from Company Portal. </p>"},{"location":"good/setup/#mac_4","title":"Mac","text":"<p>Python should be pre-installed. You can check by running <code>python3 --version</code> in the terminal. If not, install it from python.org.</p>"},{"location":"good/setup/#r-and-rstudio","title":"R and RStudio","text":""},{"location":"good/setup/#windows_5","title":"Windows","text":""},{"location":"good/setup/#for-wsl2","title":"For WSL2","text":"<p>To use RStudio from WSL2 as if native install it in linux. This command worked for me: Depending on the linux variaiton: <pre><code># you may need to install some libraries\nsudo apt-get update\nsudo apt-get install r-base\nsudo apt-get install gdebi-core\nsudo apt-get install libglib2.0-0\nsudo apt-get install libnspr4\nsudo apt-get install libnss3\nsudo apt-get install libatk1.0-0\nsudo apt-get install libatk-bridge2.0-0\nsudo apt-get install libcups2\nsudo apt-get install libcairo2\nsudo apt-get install libgtk-3-0\nsudo apt-get install libgbm1\nsudo apt-get install libasound2\nsudo apt-get install libcurl4-openssl-dev\nsudo apt-get install libssl-dev\nsudo apt-get install libfontconfig1-dev\nsudo apt-get install libharfbuzz-dev libfribidi-dev\nsudo apt-get install -y libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev libwebp-dev\nsudo apt-get install pkg-config\n\n# Either\nwget https://download1.rstudio.org/electron/jammy/amd64/rstudio-2025.09.0-387-amd64.deb\nsudo gdebi rstudio-2025.09.0-387-amd64.deb\n# or\nsudo snap install rstudio --classic\n</code></pre></p>"},{"location":"good/setup/#mac_5","title":"Mac","text":"<p>Install R from CRAN and RStudio from RStudio.</p>"},{"location":"good/setup/#install-conda-anaconda","title":"Install Conda (Anaconda)","text":""},{"location":"good/setup/#windows_6","title":"Windows","text":"<p>Install Anaconda from the Company Portal: </p>"},{"location":"good/setup/#wsl2","title":"WSL2","text":"<pre><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nchmod +x Miniconda3-latest-Linux-x86_64.sh\n./Miniconda3-latest-Linux-x86_64.sh\n</code></pre>"},{"location":"good/setup/#mac_6","title":"Mac","text":"<p>Install Anaconda from anaconda.com:</p>"},{"location":"good/setup/#install-docker","title":"Install Docker","text":""},{"location":"good/setup/#windows_7","title":"Windows","text":"<p>For Windows The application can be installed from Company Portal. </p>"},{"location":"good/setup/#mac_7","title":"Mac","text":"<p>For Mac the application can be downloaded and installed from here docker.com.</p>"},{"location":"good/setup/#see-hidden-files","title":"See Hidden Files","text":""},{"location":"good/setup/#windows_8","title":"Windows","text":"<p>For Windows The application can be installed from Company Portal. </p>"},{"location":"good/setup/#mac_8","title":"Mac","text":"<p>Inside Finder on Mac, you can show hidden files with \"Cmd + Shift + .\"</p>"},{"location":"good/setup/#install-singularity","title":"Install Singularity","text":"<p>// ...existing code...</p>"},{"location":"good/setup/#install-singularity_1","title":"Install Singularity","text":""},{"location":"good/setup/#windows_9","title":"Windows","text":"<p>Singularity/Apptainer is not natively supported on Windows. advanced users only).</p>"},{"location":"good/setup/#mac_9","title":"Mac","text":"<pre><code># Install Homebrew if not already installed\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n# Install Apptainer (successor to Singularity)\nbrew install apptainer\n</code></pre>"},{"location":"good/setup/#linux-wsl2ubuntudebian","title":"Linux (WSL2/Ubuntu/Debian)","text":"<pre><code># Install dependencies\nsudo apt update\nsudo apt install curl gnupg\n# Add repository and install\ncurl -fsSL https://download.opensuse.org/repositories/home:/apptainer/Debian_12/Release.key | sudo gpg --dearmor -o /usr/share/keyrings/apptainer-archive-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/apptainer-archive-keyring.gpg] https://download.opensuse.org/repositories/home:/apptainer/Debian_12/ /\" | sudo tee /etc/apt/sources.list.d/apptainer.list\nsudo apt update\nsudo apt install apptainer\n</code></pre> <p>Verify Installation: <pre><code># Check version\nsingularity --version\n# Test with hello world\nsingularity pull docker://hello-world\nsingularity run hello-world_latest.sif\n</code></pre> Note: Apptainer is the actively maintained successor to Singularity and is recommended for new installations.</p>"},{"location":"good/thursday/","title":"Thursday Overview: R for Reproducible Research","text":"<p>Goal: Learn how to set up a reproducible research project in R, manage your code and data responsibly, and build a simple, tested analysis pipeline using RStudio.</p>"},{"location":"good/thursday/#what-we-cover","title":"What We Cover","text":"<ul> <li>Project Setup &amp; Data Privacy: </li> <li>Reviewed a sensible folder structure for research projects.</li> <li> <p>Discussed the importance of <code>.gitignore</code> to keep sensitive or unnecessary files (like raw data and environment folders) out of version control.</p> </li> <li> <p>Version Control with Git &amp; RStudio: </p> </li> <li> <p>Used Git (with RStudio or command line) to track project changes and collaborate safely.</p> </li> <li> <p>Reproducible R Environments: </p> </li> <li> <p>Used <code>renv</code> to manage project-specific R packages, ensuring reproducibility.</p> </li> <li> <p>Downloading and Preparing Data: </p> </li> <li>Downloaded a real-world dataset from cBioPortal.</li> <li> <p>Used bash commands to organize and extract data into the project.</p> </li> <li> <p>Building a Simple R Pipeline: </p> </li> <li>Wrote clear, well-documented R functions to:<ul> <li>Load tabular data</li> <li>Clean/filter relevant columns</li> <li>Save processed data</li> <li>Analyze and plot the top 10 mutated genes</li> </ul> </li> <li> <p>Saved results and plots to the appropriate folders.</p> </li> <li> <p>Testing Your Code: </p> </li> <li>Wrote a basic test (using testthat) to check that the pipeline runs end-to-end and produces expected outputs.</li> <li> <p>Discussed the value of both unit and smoke tests for research code.</p> </li> <li> <p>Ethical Coding &amp; Documentation: </p> </li> <li>Emphasized the importance of documentation and code reuse.</li> <li>Added a README to the analysis folder to explain what each script does.</li> </ul>"},{"location":"good/thursday/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Organize your project folders and use <code>.gitignore</code> to protect sensitive data.</li> <li>Use version control (Git) for all your code and documentation.</li> <li>Always use a reproducible environment for R projects (e.g., renv).</li> <li>Write modular, well-documented code for each step of your analysis.</li> <li>Test your code to catch errors early and ensure reproducibility.</li> <li>Document your scripts and results for yourself and others.</li> </ul>"},{"location":"good/thursday/#videos-of-session","title":"Videos of session","text":"<ul> <li>Section 1/3 15.55  </li> <li>Section 2/3 17.21  </li> <li>Section 3/3 17.15 </li> </ul> <p>Homework: - Practice writing a simple R function for data loading or analysis. - Write a short test to check your function works. - Add a brief README or comments to explain your code. - Explore The Turing Way\u2019s code reuse checklist for more ideas.</p>"},{"location":"good/thursday/#session-cheat-sheet-thursday","title":"Session Cheat Sheet: Thursday","text":""},{"location":"good/thursday/#bashterminal-and-rstudio-commands","title":"Bash/Terminal and RStudio Commands","text":"<pre><code># List files and check .gitignore\nls\ncat .gitignore\n\n# Add common R exclusions to .gitignore\necho \".Rhistory\\n.RData\\n.Rproj.user/\\nrenv/\" &gt;&gt; .gitignore\ncat .gitignore\n\n# Create folders for R code and tests\nmkdir -p src/R tests/R\nls\n\n# Check git status\ngit status\n</code></pre>"},{"location":"good/thursday/#r-environment-setup","title":"R Environment Setup","text":"<pre><code># Using the R console in RStudio\ninstall.packages(\"renv\")\nrenv::init()\ninstall.packages(c(\"tidyverse\", \"testthat\"))\nrenv::snapshot()\n</code></pre>"},{"location":"good/thursday/#data-download-and-extraction","title":"Data Download and Extraction","text":"<pre><code># Using the bash terminal in R Studio or your system terminal\nmkdir -p data/raw\nwget -O data/raw/aml_tcga_gdc.tar.gz https://cbioportal-datahub.s3.amazonaws.com/aml_tcga_gdc.tar.gz\ntar -xzvf data/raw/aml_tcga_gdc.tar.gz -C data/raw\n</code></pre>"},{"location":"good/thursday/#r-code-snippets","title":"R Code Snippets","text":""},{"location":"good/thursday/#srcranalysisr","title":"src/R/analysis.R","text":"<pre><code>#!/usr/bin/env Rscript\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nload_data &lt;- function(filepath) {\n  df &lt;- read_tsv(filepath, skip = 2)\n  return(df)\n}\n\nclean_data &lt;- function(df) {\n  df &lt;- df %&gt;%\n    select(Hugo_Symbol, Variant_Classification, Tumor_Sample_Barcode) %&gt;%\n    na.omit()\n  return(df)\n}\n\nsave_data &lt;- function(df, output_path) {\n  write_csv(df, output_path)\n}\n\nanalyze_data &lt;- function(df) {\n  summary &lt;- df %&gt;%\n    count(Hugo_Symbol, sort = TRUE) %&gt;%\n    head(10)\n  print(\"Top 10 mutated genes:\")\n  print(summary)\n  p &lt;- ggplot(summary, aes(x = reorder(Hugo_Symbol, -n), y = n)) +\n    geom_bar(stat = \"identity\") +\n    xlab(\"Gene\") +\n    ylab(\"Mutation Count\") +\n    ggtitle(\"Top 10 Mutated Genes\") +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n  return(p)\n}\n\n# Example usage\n# df &lt;- load_data(\"data/raw/aml_tcga_gdc/data_mutations.txt\")\n# cleaned_df &lt;- clean_data(df)\n# save_data(cleaned_df, \"data/processed/cleaned_mutations.csv\")\n# p &lt;- analyze_data(cleaned_df)\n# ggsave(\"results/top10_mutated_genes.png\", plot = p, width = 8, height = 5)\n</code></pre>"},{"location":"good/thursday/#testsrtest_analysisr","title":"tests/R/test_analysis.R","text":"<pre><code>library(testthat)\nsource(\"../../src/R/analysis.R\")\n\ntest_that(\"pipeline smoke test\", {\n  df &lt;- data.frame(\n    Hugo_Symbol = c(\"TP53\", \"BRCA1\", \"TP53\", \"EGFR\"),\n    Variant_Classification = c(\"Missense\", \"Nonsense\", \"Missense\", \"Silent\"),\n    Tumor_Sample_Barcode = c(\"S1\", \"S2\", \"S3\", \"S4\")\n  )\n  cleaned &lt;- clean_data(df)\n  expect_true(nrow(cleaned) &gt; 0)\n  expect_true(all(c(\"Hugo_Symbol\", \"Variant_Classification\", \"Tumor_Sample_Barcode\") %in% colnames(cleaned)))\n})\n</code></pre>"},{"location":"good/thursday/#add-a-readme-to-your-analysis-folder","title":"Add a README to your analysis folder","text":"<p><code>bash</code> <pre><code>echo -e \"# Analysis Scripts\\nThis folder contains R scripts for data analysis. Each script is documented and tested.\" &gt; src/R/README.md\ncat src/R/README.md\n</code></pre></p>"},{"location":"good/thursday/#references","title":"References","text":"<ul> <li>Cerami et al. The cBio Cancer Genomics Portal: An Open Platform for Exploring Multidimensional Cancer Genomics Data. Cancer Discovery. May 2012; 401. PubMed</li> <li>Gao et al. Integrative analysis of complex cancer genomics and clinical profiles using the cBioPortal. Sci. Signal. 6, pl1 (2013). PubMed</li> <li>de Bruijn et al. Analysis and Visualization of Longitudinal Genomic and Clinical Data from the AACR Project GENIE Biopharma Collaborative in cBioPortal. Cancer Res (2023). PubMed</li> <li>DataSet: https://www.cbioportal.org/study/plots?id=aml_tcga_gdc</li> </ul>"},{"location":"good/tuesday/","title":"Tuesday Overview: Version Control and Collaboration in Research Coding","text":"<p>Goal: Understand the basics of version control with Git, set up repositories, collaborate using GitHub and GitLab, and integrate version control into your research workflow.</p>"},{"location":"good/tuesday/#what-we-cover","title":"What We Cover","text":"<ul> <li>Introduction to version control and why it matters for research</li> <li>Setting up Git and configuring your identity</li> <li>Initializing a repository and tracking changes</li> <li>Basic Git commands: <code>git add</code>, <code>git commit</code>, <code>git status</code>, <code>git log</code></li> <li>Creating and switching branches for collaborative work</li> <li>Merging branches and resolving merge conflicts</li> <li>Using GitHub and ICR GitLab for remote collaboration</li> <li>Integrating Git with VSCode and GitHub Desktop</li> <li>Best practices for team coding and project management</li> <li>Choosing a license in GitLab and GitHub</li> </ul>"},{"location":"good/tuesday/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Version control helps you track changes, collaborate, and avoid losing work.</li> <li>Git is the most widely used version control system in research and industry.</li> <li>Branching and merging allow for safe experimentation and teamwork.</li> <li>Remote repositories (GitHub, GitLab) enable collaboration and backup.</li> <li>Integrating Git with editors like VSCode streamlines your workflow.</li> </ul>"},{"location":"good/tuesday/#videos-of-session","title":"Videos of session","text":"<ul> <li>Section 1/3 8.45  </li> <li>Section 2/3 27.20  </li> <li>Section 3/3 24.30  </li> </ul>"},{"location":"good/tuesday/#session-cheat-sheet-tuesday","title":"Session Cheat Sheet: Tuesday","text":""},{"location":"good/tuesday/#setting-up-git-for-your-project","title":"Setting Up Git for Your Project","text":"<pre><code>git --version\ngit config --list\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@icr.ac.uk\"\ngit config --global init.defaultBranch main\ngit config --list\n</code></pre>"},{"location":"good/tuesday/#basic-git-commands","title":"Basic Git Commands","text":"<pre><code>cd biomarkers_project\ncode .\ngit init\ngit status\ngit add README.md\ngit commit -m \"Add README for biomarkers project\"\ngit status\n</code></pre>"},{"location":"good/tuesday/#using-git-at-icr","title":"Using Git at ICR","text":"<ul> <li>GitHub organisation:</li> <li>ICR GitLab:</li> </ul>"},{"location":"good/tuesday/#setting-up-keys-for-gitlab","title":"Setting up keys for GitLab","text":"<pre><code>ssh-keygen -t ecdsa -C \"\"\n</code></pre> <p><code>~/.ssh/config</code> <pre><code># Private GitLab instance\nHost &lt;your_usernames&gt;.git.icr.ac.uk\n  PreferredAuthentications publickey\n  IdentityFile ~/.ssh/id_ecdsa\n</code></pre></p>"},{"location":"good/tuesday/#using-the-gitlab-repository-for-your-project","title":"Using the GitLab repository for your project","text":"<pre><code>git init --initial-branch=main\ngit remote add origin git@git.icr.ac.uk:ralcraft/biomarkers_project.git\ngit add .\ngit commit -m \"Initial commit\"\ngit push --set-upstream origin main\n</code></pre>"},{"location":"good/tuesday/#working-with-branches","title":"Working with Branches","text":"<pre><code>git branch experiment\ngit checkout experiment\necho \"# Testing a new analysis\" &gt; test.txt\ngit add test.txt\ngit commit -m \"Add test analysis file\"\ngit checkout main\ngit merge experiment\n# To merge in changes from main\ngit pull origin main\ngit merge origin/main\n# Resolve conflicts if needed\ngit push\n</code></pre>"},{"location":"good/tuesday/#collaborating-with-others","title":"Collaborating with Others","text":"<pre><code># Clone a repository (example)\ngit clone https://git.icr.ac.uk/yourusername/biomarkers_project.git\n# Pull latest changes\ngit pull\n# Push your changes\ngit push\n</code></pre>"},{"location":"good/tuesday/#homework","title":"Homework","text":"<ul> <li>Practice basic Git commands on your project</li> <li>Try creating and merging branches</li> <li>Set up a remote repository and push your changes</li> <li>Review the version control section in The Turing Way handbook</li> </ul>"},{"location":"good/tuesday/#reflection","title":"Reflection","text":"<ul> <li>How does version control help you track changes and collaborate?</li> <li>What challenges did you encounter with branching or merging?</li> <li>How will you use Git in your future research projects?</li> </ul> <p>Complete these tasks before the next session to build confidence with version control and collaboration tools.</p>"},{"location":"good/wednesday/","title":"Wednesday Overview: Python for Reproducible Research","text":"<p>Goal: Learn how to set up a reproducible research project in Python, manage your code and data responsibly, and build a simple, tested analysis pipeline.</p>"},{"location":"good/wednesday/#what-we-cover","title":"What We Cover","text":"<ul> <li>Project Setup &amp; Data Privacy: </li> <li>Reviewed a sensible folder structure for research projects.</li> <li> <p>Discussed the importance of <code>.gitignore</code> to keep sensitive or unnecessary files (like raw data and environment folders) out of version control.</p> </li> <li> <p>Version Control with Git &amp; VSCode: </p> </li> <li> <p>Used Git (with VSCode or command line) to track project changes and collaborate safely.</p> </li> <li> <p>Python Virtual Environments: </p> </li> <li> <p>Created a virtual environment to manage project-specific Python packages, ensuring reproducibility.</p> </li> <li> <p>Downloading and Preparing Data: </p> </li> <li>Downloaded a real-world dataset from cBioPortal.</li> <li> <p>Used bash commands to organize and extract data into the project.</p> </li> <li> <p>Building a Simple Python Pipeline: </p> </li> <li>Wrote clear, well-documented Python functions to:<ul> <li>Load tabular data</li> <li>Clean/filter relevant columns</li> <li>Save processed data</li> <li>Analyze and plot the top 10 mutated genes</li> </ul> </li> <li> <p>Saved results and plots to the appropriate folders.</p> </li> <li> <p>Testing Your Code: </p> </li> <li>Wrote a basic test (using pytest) to check that the pipeline runs end-to-end and produces expected outputs.</li> <li> <p>Discussed the value of both unit and smoke tests for research code.</p> </li> <li> <p>Ethical Coding &amp; Documentation: </p> </li> <li>Emphasized the importance of documentation and code reuse.</li> <li>Added a README to the analysis folder to explain what each script does.</li> </ul>"},{"location":"good/wednesday/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Organize your project folders and use <code>.gitignore</code> to protect sensitive data.</li> <li>Use version control (Git) for all your code and documentation.</li> <li>Always use a virtual environment for Python projects.</li> <li>Write modular, well-documented code for each step of your analysis.</li> <li>Test your code to catch errors early and ensure reproducibility.</li> <li>Document your scripts and results for yourself and others.</li> </ul>"},{"location":"good/wednesday/#videos-of-session","title":"Videos of session","text":"<ul> <li>Section 1/3 21.19  </li> <li>Section 2/3 15.06  </li> <li>Section 3/3 19.43  </li> </ul> <p>Homework: - Practice writing a simple Python function for data loading or analysis. - Write a short test to check your function works. - Add a brief README or comments to explain your code. - Explore The Turing Way\u2019s code reuse checklist for more ideas.</p>"},{"location":"good/wednesday/#session-cheat-sheet-wednesday","title":"Session Cheat Sheet: Wednesday","text":""},{"location":"good/wednesday/#bashterminal-commands","title":"Bash/Terminal Commands","text":"<pre><code># List files and check .gitignore\nls\ncat .gitignore\n\n# Add common Python exclusions to .gitignore\necho \"__pycache__/\\n*.pyc\\nenvironment/\" &gt;&gt; .gitignore\ncat .gitignore\n\n# Create folders for Python code and tests\nmkdir -p src/python tests/python\nls\n\n# Check git status\ngit status\n\n# Create and activate a Python virtual environment\npython3 -m venv environment\nsource environment/bin/activate\n\n# Install required Python packages\npip install pandas pytest matplotlib\npip freeze &gt; environment/requirements.txt\n\n# Download and extract a dataset from cBioPortal\nmkdir -p data/raw\nwget -O data/raw/aml_tcga_gdc.tar.gz https://cbioportal-datahub.s3.amazonaws.com/aml_tcga_gdc.tar.gz\ntar -xzvf data/raw/aml_tcga_gdc.tar.gz -C data/raw\n\n# Run your analysis script\npython src/python/analysis.py\n\n# Run your tests\npytest\n</code></pre>"},{"location":"good/wednesday/#python-code-snippets","title":"Python Code Snippets","text":""},{"location":"good/wednesday/#srcpythonanalysispy","title":"src/python/analysis.py","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.use('Agg')\n\ndef load_data(filepath):\n    \"\"\"Load a tab-delimited file and return a DataFrame.\"\"\"\n    df = pd.read_csv(filepath, sep='\\t', header=2)\n    return df\n\ndef clean_data(df):    \n    df = df[['Hugo_Symbol', 'Variant_Classification', 'Tumor_Sample_Barcode']]\n    df = df.dropna()        \n    return df\n\ndef save_data(df, output_path):\n    df.to_csv(output_path, index=False)\n\ndef analyze_data(df):\n    summary = df['Hugo_Symbol'].value_counts().head(10)\n    print(\"Top 10 mutated genes:\")\n    print(summary)\n    fig, ax = plt.subplots()\n    summary.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Gene')\n    ax.set_ylabel('Mutation Count')\n    ax.set_title('Top 10 Mutated Genes')\n    return fig\n\nif __name__ == \"__main__\":\n    df = load_data(\"data/raw/aml_tcga_gdc/data_mutations.txt\")\n    cleaned_df = clean_data(df)\n    save_data(cleaned_df, \"data/processed/cleaned_mutations.csv\")\n    fig = analyze_data(cleaned_df)\n    fig.savefig('results/top10_mutated_genes.png')\n</code></pre>"},{"location":"good/wednesday/#testspythontest_analysispy","title":"tests/python/test_analysis.py","text":"<pre><code>import os\nimport sys\nfrom pathlib import Path\nimport pandas as pd\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\nfrom src.python.analysis import load_data, clean_data, save_data, analyze_data\n\ndef create_test_data(tmp_path):\n    df = pd.DataFrame({\n        'Hugo_Symbol': ['TP53', 'BRCA1', 'TP53', 'EGFR'],\n        'Variant_Classification': ['Missense', 'Nonsense', 'Missense', 'Silent'],\n        'Tumor_Sample_Barcode': ['S1', 'S2', 'S3', 'S4']\n    })\n    input_file = tmp_path / 'test_mutations.txt'\n    with open(input_file, 'w') as f:\n        f.write(\"# The cBioPortalFiles\\n\")\n        f.write(\"# Have 2 comment rows before the dataframe\\n\")        \n    df.to_csv(input_file, sep='\\t', index=False, mode='a')\n    return input_file\n\ndef test_pipeline_smoke(tmp_path=Path(\".\")):    \n    input_file = create_test_data(tmp_path)        \n    loaded = load_data(input_file)    \n    cleaned = clean_data(loaded)\n    output_file = tmp_path / 'cleaned.csv'\n    save_data(cleaned, output_file)\n    fig = analyze_data(cleaned)\n    plot_file = tmp_path / 'plot.png'\n    fig.savefig(plot_file)\n    assert os.path.exists(output_file)\n    out_df = pd.read_csv(output_file)\n    assert not out_df.empty\n    assert set(['Hugo_Symbol', 'Variant_Classification', 'Tumor_Sample_Barcode']).issubset(out_df.columns)\n    assert os.path.exists(plot_file)\n</code></pre>"},{"location":"good/wednesday/#add-a-readme-to-your-analysis-folder","title":"Add a README to your analysis folder","text":"<pre><code>echo -e \"# Analysis Scripts\\nThis folder contains Python scripts for data analysis. Each script is documented and tested.\" &gt; src/python/README.md\ncat src/python/README.md\n</code></pre>"},{"location":"good/wednesday/#references","title":"References","text":"<ul> <li>Cerami et al. The cBio Cancer Genomics Portal: An Open Platform for Exploring Multidimensional Cancer Genomics Data. Cancer Discovery. May 2012; 401. PubMed</li> <li>Gao et al. Integrative analysis of complex cancer genomics and clinical profiles using the cBioPortal. Sci. Signal. 6, pl1 (2013). PubMed</li> <li>de Bruijn et al. Analysis and Visualization of Longitudinal Genomic and Clinical Data from the AACR Project GENIE Biopharma Collaborative in cBioPortal. Cancer Res (2023). PubMed</li> <li>DataSet: https://www.cbioportal.org/study/plots?id=aml_tcga_gdc</li> </ul>"},{"location":"good/instructor/01_monday/","title":"Monday Live Coding Script: Good-Practices in Research Coding","text":"<p>instructor home</p>"},{"location":"good/instructor/01_monday/#monday-session-timings-instructor-guide","title":"Monday Session Timings (Instructor Guide)","text":"Part Section(s) Covered Suggested Time Running Time 1 Opening, Welcome &amp; The Turing Way 10 min 10 2 Command Line Basics (starting terminal, navigation, file/folder management, nano) 15 min 25 3 Advanced Command Line &amp; HPC (advanced commands, logging into Alma, compute nodes) 15 min 40 4 Project Structure &amp; VSCode (making folders, using VSCode, adding files/scripts) 15 min 55 5 Bash Scripting, Remote Access, Wrap-up &amp; Homework 5 min 60"},{"location":"good/instructor/01_monday/#pre-session-setup","title":"Pre-Session Setup","text":"<p>[ASIDE: Have open and visible: 1) Prerequsites: https://icr-sc.github.io/good-practice/good/setup/ 2) Summary: https://icr-sc.github.io/good-practice/good/overview/ 3) Monday: https://icr-sc.github.io/good-practice/good/monday/ 4) Turing Way: https://book.the-turing-way.org/ 5) Have terminal 6) VSCode open Have a clean desktop/folder structure visible.] </p>"},{"location":"good/instructor/01_monday/#part-1-opening-welcome-and-the-turing-way","title":"Part 1 Opening, Welcome and the Turing Way","text":"<p>Good morning everyone! Welcome to our first session in the 'good-practices in research coding' series. Today we're going to get started with the command line and VSCode. This session is designed for beginners, but even if you have experience, you'll get a refresher and see how things work at our institution.</p> <p>Introduce yourself and the RSE team members present.</p> <p>These sessions are designed as follow-along sessions, a form of participatory live coding. Realistically you may not be following along now as they are designed also for your lunch break. The sessions &gt;are recorded, so you can watch back and follow along when it is most convenient for you.  If you are following along live, type any questions in the chat and one of the RSE team members will do their best to help you as it goes.  We are happy to help you with any of these sessions afterwards, just get in touch or come along to one of &gt;our drop in sessions on Monday or Tuesday lunch times.</p> <p>The Turing Way is an open-source guide to reproducible, ethical, and collaborative research. It helps us make our work understandable and reusable by others. We will &gt;refer to these principles as we go through our sessions this week.\"</p>"},{"location":"good/instructor/01_monday/#part-2-command-line-basics","title":"Part 2: Command line basics","text":"<p>Let's open a command line. I'll be using Windows, with a mix of WSL2 and Powershell. If you're on Mac or Linux, you can use the built-in Terminal.\"</p> <p>How to open a terminal: - Windows: Search for 'WSL' or 'Powershell' in the Start menu - Mac: Use Spotlight (Cmd+Space), type 'Terminal' - Linux: Ctrl+Alt+T or search for 'Terminal'</p> <p>[ASIDE: Show your terminal. Wait for participants to open theirs. Troubleshoot any issues quickly.]</p> <p>Let's try some very basic commands. Type what I type.\"</p> <pre><code># Where am I?\npwd\n# List files and folders\nls\n# Make a new folder for practice\nmkdir test_folder\n# Go into it\ncd test_folder\n# Make a file\ntouch example.txt\n# See the file\nls\n</code></pre>"},{"location":"good/instructor/01_monday/#editing-a-file-with-nano","title":"Editing a File with nano","text":"<p>If you want to quickly edit a file from the command line, you can use the <code>nano</code> editor. For example, after creating a file with <code>touch example.txt</code>, type:</p> <pre><code>nano example.txt\n</code></pre> <p>This opens the file in a simple editor. Type your text, then press <code>Ctrl+O</code> to save and <code>Ctrl+X</code> to exit. You can then type:</p> <pre><code>cat example.txt\n</code></pre> <p>to see the contents of your file printed in the terminal. These commands help you navigate and create files and folders. If you get lost, use <code>pwd</code> to see where you are.</p>"},{"location":"good/instructor/01_monday/#part-3-advanced-command-line-hpc","title":"Part 3: Advanced Command Line &amp; HPC","text":"<p>Let's try a few more useful commands. Don't worry if you haven't seen these before!</p> <pre><code># See hidden files\nls -la\n# Make several folders at once\nmkdir -p data/{raw,processed}\n# See your folder structure\nls\n# Remove a file\nrm example.txt\n# Go up a folder\ncd ..\n</code></pre> <p>Now let's log into our HPC cluster, Alma. This is where we run big analyses.</p> <pre><code>ssh &lt;username&gt;@alma.icr.ac.uk\n</code></pre> <p>You'll need your username and password. If you have trouble, let us know. I have an ssh key set up in windows but not WSL2, you cans ee that in windows I can log straight in but in Ubuntu I need a password.</p> <p>On Alma, there are login nodes (for connecting and setting up) and compute nodes (for running jobs). To access a compute node for interactive work, use this command:</p> <pre><code>srun --pty -t 12:00:00 --cpus-per-task 1 --mem-per-cpu 4021 --partition interactive bash\nsqueue -u $USER\n</code></pre> <p>Now you're on a compute node and can run your analysis. I am going to type exit to return to the login node and exit again to return to my local computer.</p>"},{"location":"good/instructor/01_monday/#part-4-project-structure-vscode","title":"Part 4: Project Structure &amp; VSCode","text":"<p>Let's go back to our own computer and make a folder for a reproducible project. We'll use VSCode to work in it.</p> <pre><code>cd ..\nrm -rf test_folder\nmkdir biomarkers_project\ncd biomarkers_project\ncode .\n</code></pre> <p>VSCode will open in your project folder. You can use the built-in terminal to run the same commands we've just learned.</p>"},{"location":"good/instructor/01_monday/#part-18-45-min-5-min","title":"Part 1.8 (45 min-5 min)","text":""},{"location":"good/instructor/01_monday/#making-a-sensible-project-structure","title":"Making a Sensible Project Structure","text":"<p>Let's quickly make a sensible folder structure for a biomarkers project. We'll talk more about project structure and data sensitivity next time.</p> <pre><code>mkdir -p data/{raw,processed} src docs results tests environment\nls\n</code></pre>"},{"location":"good/instructor/01_monday/#part-19-50-min-5-min","title":"Part 1.9 (50 min-5 min)","text":""},{"location":"good/instructor/01_monday/#adding-a-file","title":"Adding a file","text":"<p>Let's add a README file to our project to describe it.</p> <p><pre><code>touch README.md\nls\n</code></pre> Now you can see that I don't need to use nano to edit this file as I can use VSCode to do that.</p>"},{"location":"good/instructor/01_monday/#part-5-bash-scripting-remote-access-wrap-up-homework","title":"Part 5: Bash Scripting, Remote Access, Wrap-up &amp; Homework","text":"<p>Let\u2019s create some very simple data files in our <code>data/raw</code> directory, and then write a bash script to \u201cprocess\u201d them into <code>data/processed</code>. I could crate the visually but it is easier to do it from the command line so I will do that.</p> <pre><code># Make sure you are in your project folder\ncd biomarkers_project\n\n# Create the raw and processed directories if they don't exist\nmkdir -p data/raw data/processed\n\n# Create a simple data file in data/raw\necho -e \"id,value\\n1,10\\n2,20\" &gt; data/raw/data1.csv\n</code></pre> <p>This is a bash command that creates a new CSV file called data1.csv in the data/raw directory. It &gt;writes two rows of data (with a header row) into the file. The -e flag allows interpretation &gt;of the \\n as newlines. We can see the file in VSCode.:</p> <p>If I arrow up I get the last command and I can edit it to quickly create 3 more files <pre><code>echo -e \"id,value\\n3,30\\n4,40\" &gt; data/raw/data2.csv\necho -e \"id,value\\n5,50\\n6,60\" &gt; data/raw/data3.csv\necho -e \"id,value\\n7,70\\n8,80\" &gt; data/raw/data4.csv\n</code></pre></p> <p>Now let\u2019s write a very simple bash script that \u201cprocesses\u201d these files. For now, it will just print a message for each file (you could also copy them if you want):</p> <pre><code># Create a script called process_data.sh\ntouch src/process_data.sh\n</code></pre> <p>Paste the following into the script:</p> <pre><code>#!/bin/bash\nfor file in data/raw/*.csv; do\n    echo \"Processing $file\" \n    # Uncomment the next line to actually copy the files\n    # cp \"$file\" data/processed/    \ndone\n</code></pre> <p>The first line is called a \"shebang\" (or hashbang) line. It should be the very first line in a script file. It tells the operating system to use the Bash shell to interpret and run the script that follows. This ensures that when you execute the script (e.g., with ./process_data.sh), it will be run using Bash, regardless of your default shell.</p> <p>Make the script executable and run it:</p> <pre><code>chmod +x process_data.sh\n./process_data.sh\n</code></pre> <p>You should see a message for each file. If you want, you can uncomment the <code>cp</code> line in the script to actually copy the files to <code>data/processed</code>.</p> <p>Finally we will look at using VScode with Alma using remote-ssh on VSCode.  This is not something that everyone will do so you may just be interested to watch and see that it is possible. To do this you will need to have followed the set up for remote-ssh in the pre-requisites.  You will also need to have your ssh keys set up on Alma.  If you have not done this please let us know and we can help you with it.</p> <p>Show the link: https://almacookbook.github.io/ides/remote/</p> <p>[ASIDE: Demonstrate remote-ssh connection to Alma in VSCode. Show how to open a terminal and navigate the file system on Alma.]</p> <p>[ASIDE: Also, as an alternative show using the terminal in git and also using scratch for git pull]</p>"},{"location":"good/instructor/01_monday/#session-wrap-up-homework","title":"Session Wrap-up &amp; Homework","text":"<p>You've learned how to use the command line, log into Alma, and set up a basic project folder. Next time, we'll go deeper into project structure and data sensitivity.</p>"},{"location":"good/instructor/01_monday/#homework-session-consolidation","title":"Homework (Session Consolidation):","text":"<ul> <li>Practice opening your terminal and running the basic commands (<code>pwd</code>, <code>ls</code>, <code>mkdir</code>, <code>cd</code>)</li> <li>Try logging into Alma if you have access</li> <li>Create a simple project folder and open it in VSCode</li> </ul> <p>See you next session!</p>"},{"location":"good/instructor/02_tuesday/","title":"Tuesday Live Coding Script: Good-Practices in Research Coding","text":"<p>instructor home</p>"},{"location":"good/instructor/02_tuesday/#monday-session-timings-instructor-guide","title":"Monday Session Timings (Instructor Guide)","text":"Part Section(s) Covered Suggested Time Running Time 1 Opening, Welcome &amp; Introduction to Version Control 10 min 10 2 Setting Up Git &amp; Basic Commands (config, init, add, commit, status, log) 15 min 25 3 Remote Repositories &amp; Collaboration (GitHub, GitLab, SSH keys, pushing, pulling) 15 min 40 4 Branching, Merging &amp; Conflict Resolution 15 min 55 5 Best Practices, Project Boards, Wrap-up &amp; Homework 10 min 65"},{"location":"good/instructor/02_tuesday/#pre-session-setup","title":"Pre-Session Setup","text":"<p>[ASIDE: Have terminal, VSCode, and browser tabs open for GitHub and ICR GitLab. Make sure yesterday's biomarkers project is available. Check that participants have Git installed.]</p> <p>1) Prerequsites: https://icr-sc.github.io/good-practice/good/setup/ 2) Summary: https://icr-sc.github.io/good-practice/good/overview/ 3) Tuesday: https://icr-sc.github.io/good-practice/good/tuesday/ 4) Turing Way: https://book.the-turing-way.org/ 5) Have terminal 6) VSCode open Have a clean desktop/folder structure visible.]**  </p>"},{"location":"good/instructor/02_tuesday/#part-1-opening-welcome-and-introduction-to-version-control","title":"Part 1: Opening, Welcome and Introduction to Version Control","text":"<p>\"Good morning! Yesterday we set up our project folders and learned some command line basics. Today, we're going to learn about git, the tool that helps us keep track of changes and work together on research code. We'll use examples from our own institution, ICR.\"</p> <p>\"Git is a tool that helps you save versions of your code and documents, so you can go back in time, undo mistakes, and work with others. It's like a super-powered undo button for your research project.\"</p> <p>\"Let's check if git is installed and set up your name and email.\"</p>"},{"location":"good/instructor/02_tuesday/#what-i-type-live-coding","title":"What I Type (Live Coding):","text":"<pre><code>git --version\ngit config --list\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@icr.ac.uk\"\ngit config --global init.defaultBranch main\ngit config --list\n</code></pre> <p>Let's turn our biomarkers project into a git repository and learn the basic commands. I am going to do this from the VSCode command line terminal.</p>"},{"location":"good/instructor/02_tuesday/#cd-biomarkers_project-code-git-init-git-status-git-add-readmemd-git-commit-m-add-readme-for-biomarkers-project-git-status","title":"<pre><code>cd biomarkers_project\ncode .\ngit init\ngit status\ngit add README.md\ngit commit -m \"Add README for biomarkers project\"\ngit status\n</code></pre>","text":""},{"location":"good/instructor/02_tuesday/#part-2-setting-up-git-basic-commands","title":"Part 2: Setting Up Git &amp; Basic Commands","text":"<p>At ICR, we use both GitHub and our internal GitLab for sharing code.</p> <p>GitHub organisation: https://github.com/enterprises/icr/organizations ICR GitLab: https://git.icr.ac.uk/</p> <p>You can create a repository on either platform. For sensitive or internal work, use ICR GitLab. For public or collaborative projects, GitHub is also available.</p>"},{"location":"good/instructor/02_tuesday/#setting-up-keys-for-gitlab","title":"Setting up keys for GitLab","text":"<p>You need to set up an ssh key for GitLab. You can follow the instructions here: https://git.icr.ac.uk/help/ssh/README</p> <pre><code>ssh-keygen -t ecdsa -C \"\"\n</code></pre> <p>This will create a key file ~/.ssh/id_ecdsa.pub. Copy the content of this file to gitlab (via web interface) in User/Preference/SSH Keys &gt; Add new key</p> <p><code>~/.ssh/config</code> <pre><code># Private GitLab instance\nHost &lt;your_usernames&gt;.git.icr.ac.uk\n  PreferredAuthentications publickey\n  IdentityFile ~/.ssh/id_ecdsa\n</code></pre></p>"},{"location":"good/instructor/02_tuesday/#using-the-gitlab-repository-for-your-project","title":"Using the gitlab repository for your project","text":"<p>I am going to use GitLab for this example. I am now going to go to GitLab and create a project somewhere I think is sensible: https://git.icr.ac.uk/ralcraft/biomarkers_project Follow the instructions when I created an empty proect</p> <pre><code>git init --initial-branch=main\ngit remote add origin git@git.icr.ac.uk:ralcraft/biomarkers_project.git\ngit add .\ngit commit -m \"Initial commit\"\ngit push --set-upstream origin main\n</code></pre> <p>I could have done this a different way but first creating the project in gitlab and cloning it, which is the way I would usually work. One of the reasons for this is that when I create a project through the GitLab or GitHub web interface it will create some of the skepeketin that I want such as a readme and .gitiognore file. Another important file I want is the LICENSE.md file. This is a text file that describes the license under which I am sharing my code. There are many different licenses, and you can find out more about them here: https://choosealicense.com/. I am going to go to main page in GitLab and create a LICENSE.md file, this will automatically give me the license picker.I will choose the MIT license as it is simple and permissive. A license is necessary if you want to share your code with others.</p>"},{"location":"good/instructor/02_tuesday/#using-git-in-ides","title":"Using Git in IDEs","text":"<p>You can use git inside VSCode or RStudio. Both have built-in tools to help you see changes, commit, and push without using the command line.</p> <p>[ASIDE: Show VSCode Source Control panel.] [Show a change to the readme file being made and how it looks]</p>"},{"location":"good/instructor/02_tuesday/#using-github-desktop","title":"Using GitHub Desktop","text":"<p>GitHub Desktop is a simple app for managing git visually. You can use it with both GitHub and GitLab repositories. It also can give you a colsolidated visual overview if you use multiple different apps like jpyter, vscode and rsudio.</p> <p>[ASIDE: Show GitHub Desktop or screenshots. Demonstrate opening the biomarkers project show how it looks with the waiting commit, which we will do from VSCode.]</p>"},{"location":"good/instructor/02_tuesday/#part-3-remote-repositories-collaboration","title":"Part 3: Remote Repositories &amp; Collaboration","text":"<p>Branches let you try new ideas without breaking your main code.  Branches and the flow are a big topic and there are many ways to use them for different project types.  An example of 6 different methods is here: https://dev.to/juniourrau/6-types-of-git-branching-strategy-g54 Here I will just show a simple example of making a branch, switching to it, making a change and then merging it back to main.</p> <pre><code>git branch experiment\ngit checkout experiment\necho \"# Testing a new analysis\" &gt; test.txt\ngit add test.txt\ngit commit -m \"Add test analysis file\"\ngit checkout main\ngit merge experiment\n</code></pre>"},{"location":"good/instructor/02_tuesday/#aside-look-at-how-this-looks-in-the-tool-i-have-used","title":"[Aside Look at how this looks in the tool I have used]","text":""},{"location":"good/instructor/02_tuesday/#forgetting-a-commit-message","title":"Forgetting a commit message","text":"<p>Forgetting a commit message is something that happens to everyone. Here are some ways to fix it. I create a change to the test.sh file then visually commit it without a message. I type the commit at the top and simply close the file down</p> <p>? DO it again and this time through the command line, make another change</p> <pre><code># Make a commit without a message\ngit add .\ngit commit\n</code></pre> <p>Nano pops up and I do the same thing as I did, enter and close</p>"},{"location":"good/instructor/02_tuesday/#resolving-a-merge-conflict","title":"Resolving a Merge Conflict","text":"<p>Merge conflicts are one of the most common fears in git, but they're just git's way of asking for your help when two people change the same part of a file. Let's see how to create and fix a simple conflict.</p> <pre><code># On main branch, edit README.md in vscode\ngit add README.md\ngit commit -m \"Edit README on main branch\"\n\n# Create and switch to a new branch\ngit checkout -b conflict-demo\n# Edit the same line in README.md in vscode\ngit add README.md\ngit commit -m \"Edit README on conflict-demo branch\"\n\n# Switch back to main\ngit checkout main\n# edit readme  in vscode\ngit add README.md\ngit commit -m \"Another edit on main branch\"\n\n# Try to merge conflict-demo into main\ngit merge conflict-demo\n# Git will report a conflict in README.md\n</code></pre> <p>Git will stop and show a conflict in README.md. Open the file and you'll see both versions marked like this</p> <pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nAnother change on main branch.\n=======\nThis is the conflict-demo branch version.\n&gt;&gt;&gt;&gt;&gt;&gt; conflict-demo\n</code></pre> <p>Edit the file to keep what you want (or combine both), then save it.\"</p> <pre><code># After editing README.md to resolve the conflict:\ngit add README.md\ngit commit -m \"Resolve merge conflict in README.md\"\n</code></pre> <p>That's it! Merge conflicts are normal and just mean git needs your help. Take your time, read the markers, and choose what you want to keep.</p>"},{"location":"good/instructor/02_tuesday/#part-5-good-practices-for-research-projects","title":"Part 5: Good Practices for Research Projects","text":"<p>To work with others, you can clone a repository, pull changes, and push your own updates.</p> <pre><code># Clone a repository (example)\ngit clone https://git.icr.ac.uk/yourusername/biomarkers_project.git\n# Pull latest changes\ngit pull\n# Push your changes\ngit push\n</code></pre>"},{"location":"good/instructor/02_tuesday/#gitignore-files","title":"gitignore files","text":"<p>You may remember that when we created the csv files I observed that we should not put raw data files in git. We can do this by using a .gitignore file. This is a simple text file called .gitignore that lists patterns for files and folders that git should ignore.</p> <p>```text</p>"},{"location":"good/instructor/02_tuesday/#ignore-all-csv-files","title":"Ignore all CSV files","text":"<p>*.csv  ```bash</p>"},{"location":"good/instructor/02_tuesday/#project-boards","title":"Project boards","text":"<p>ICR GitLab and GitHub both have project boards and issues to help you manage tasks and issues. You can create cards for tasks, assign them to team members, and track progress. [ASIDE: Show GitHub or GitLab project board examples.]</p>"},{"location":"good/instructor/02_tuesday/#summary","title":"Summary","text":"<ul> <li>Commit often with clear messages</li> <li>Don't put raw data or sensitive files in git</li> <li>Use branches for new ideas, there are many ways to use brances for different projject types</li> <li>Always pull before you push</li> <li>Use .gitignore to keep your repository clean</li> </ul>"},{"location":"good/instructor/02_tuesday/#session-wrap-up-homework-starts-at-60-min-takes-3-min","title":"Session Wrap-up &amp; Homework (starts at 60 min, takes 3 min)","text":""},{"location":"good/instructor/02_tuesday/#what-i-say","title":"What I Say:","text":"<p>\"Great job today! You've learned the basics of git, how to use it at ICR, and how to work with others. Next time, we'll build on this with more coding and analysis.\"</p>"},{"location":"good/instructor/02_tuesday/#homework-session-consolidation","title":"Homework (Session Consolidation):","text":"<ul> <li>Practice the basic git commands (<code>init</code>, <code>add</code>, <code>commit</code>, <code>status</code>) in your biomarkers project</li> <li>Try making a branch and merging it</li> <li>Explore the ICR GitLab or GitHub organisation</li> </ul> <p>See you next session!</p>"},{"location":"good/instructor/03_wednesday/","title":"Wednesday Session: Python for Reproducible Research (Beginner Edition)","text":""},{"location":"good/instructor/03_wednesday/#live-coding-script-for-instructors","title":"Live Coding Script for Instructors","text":"<p>Duration: 60 minutes | Format: Participatory live coding Homework: Build a simple, reproducible analysis pipeline in Python</p>"},{"location":"good/instructor/03_wednesday/#session-overview-timing-guide","title":"Session Overview &amp; Timing Guide","text":"Section Time (min) Start Time Description 1. Project Setup &amp; Data Privacy 10 0 Folder structure, .gitignore, and data privacy basics 2. Git &amp; Virtual Environment Setup 10 10 Git tracking in VSCode, creating and using a Python venv 3. Writing Reproducible Python Code (Pipeline) 20 20 Downloading data, writing/structuring analysis code, pipeline 4. Basic Testing 10 40 Writing and running simple tests with pytest 5. Ethics, Documentation &amp; Homework 10 50 Code documentation, ethical coding, session wrap-up, homework"},{"location":"good/instructor/03_wednesday/#reference","title":"Reference","text":"<p>This session builds on principles from The Turing Way: Code Reuse, a guide to making research code transparent, ethical, and reusable.</p>"},{"location":"good/instructor/03_wednesday/#pre-session-setup","title":"Pre-Session Setup","text":"<p>[ASIDE: Open VSCode in your project folder from Monday/Tuesday. Ensure Python is installed and available. Have a terminal ready.]</p>"},{"location":"good/instructor/03_wednesday/#opening-welcome","title":"Opening &amp; Welcome","text":"<p>Welcome! Today we\u2019ll use Python to analyze data in a way that\u2019s reproducible and ethical. We\u2019ll keep things simple and practical, with tips for both beginners and those wanting a refresher.\"</p>"},{"location":"good/instructor/03_wednesday/#part-31-starts-at-0-min-takes-10-min-project-setup-data-privacy","title":"Part 3.1 (starts at 0 min, takes 10 min): Project Setup &amp; Data Privacy","text":"<p>\"Let's review our project folder structure and talk about data privacy. It's important to keep sensitive data out of version control.\"</p> <pre><code>ls\ncat .gitignore\n</code></pre> <p>\"We use a <code>.gitignore</code> file to protect sensitive data and keep our code clean. Let's add some common Python exclusions.\"</p>"},{"location":"good/instructor/03_wednesday/#echo-__pycache__npycnenvironment-gitignore-cat-gitignore","title":"<pre><code>echo \"__pycache__/\\n*.pyc\\nenvironment/\" &gt;&gt; .gitignore\ncat .gitignore\n</code></pre>","text":"<p>We also want to make sure we have the folders for python.</p> <pre><code>mkdir -p src/python tests/python\nls\n</code></pre>"},{"location":"good/instructor/03_wednesday/#part-32-starts-at-10-min-takes-5-min-setting-up-git-in-vscode","title":"Part 3.2 (starts at 10 min, takes 5 min): Setting Up Git in VSCode","text":"<p>Now let's make sure our project is tracked with git. VSCode makes this easy.\" [EDIT: Open the Source Control panel in VSCode. Show the tracking]</p>"},{"location":"good/instructor/03_wednesday/#what-i-type-live-coding","title":"What I Type (Live Coding):","text":"<pre><code>git status\n</code></pre>"},{"location":"good/instructor/03_wednesday/#part-33-starts-at-15-min-takes-5-min-creating-a-python-virtual-environment","title":"Part 3.3 (starts at 15 min, takes 5 min): Creating a Python Virtual Environment","text":"<p>A virtual environment keeps your project dependencies organized and reproducible. Let's create one.\"</p> <pre><code>python3 -m venv environment\nsource environment/bin/activate\npip install pandas pytest matplotlib\npip freeze &gt; environment/requirements.txt\n</code></pre> <p>Remember to add <code>environment/</code> to your <code>.gitignore</code> so it doesn't get tracked by git.\"</p>"},{"location":"good/instructor/03_wednesday/#part-34-starts-at-20-min-takes-15-min-writing-simple-reproducible-python-code","title":"Part 3.4 (starts at 20 min, takes 15 min): Writing Simple, Reproducible Python Code","text":"<p>Let's download a public dataset so that we have something a little meaningful to work with. We can use bash to do this and download from cBioPortal here: https://www.cbioportal.org/datasets. We will use this set: Acute Myeloid Leukemia (TARGET GDC, 2025) which is 66MB. <pre><code>mkdir -p data/raw\nwget -O data/raw/aml_tcga_gdc.tar.gz https://cbioportal-datahub.s3.amazonaws.com/aml_tcga_gdc.tar.gz\ntar -xzvf data/raw/aml_tcga_gdc.tar.gz -C data/raw\n</code></pre> This has extracted a fair amount of data. We won't use all of it but we can use some for our examples, let's use the file: <code>data/raw/aml_tcga_gdc/data_mutatations.txt</code>. You can see now how important it was that we added all the files in raw to our .gitognore as I don't need to worry that I might accidentally commit them all to the GitLab cloud.</p> <p>Let's write a simple function to load data. Clear function names and documentation help others understand your code. Create <code>src/python/analysis.py</code>:</p> <pre><code>import pandas as pd\n\ndef load_data(filepath):\n    \"\"\"Load a tab-delimited file and return a DataFrame.\"\"\"\n    df = pd.read_csv(filepath, sep='\\t', header=2)\n    return df\n\nif __name__ == \"__main__\":\n    # Example usage\n    df = load_data(\"data/raw/aml_tcga_gdc/data_mutations.txt\")\n    print(df.head())\n</code></pre> <p>We can run this script directly from VSCode or in the terminal Use the Play button on the menu, or from the terminal type: <pre><code>python src/python/analysis.py\n</code></pre> If I add a python shebang I don't need to specify python <pre><code>#!/usr/bin/env python3\n</code></pre></p>"},{"location":"good/instructor/03_wednesday/#let-is-make-this-a-simple-pipeline","title":"Let is make this a simple pipeline","text":"<p>In a simple pipeline we migth load the data, clean the data, save the data analyse the data and create results. Let is create a function for each of these steps. We will keep it simple and just filter the data to a some fields and save that filtered data.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.use('Agg')\n\ndef load_data(filepath):\n    \"\"\"Load a tab-delimited file and return a DataFrame.\"\"\"\n    df = pd.read_csv(filepath, sep='\\t', header=2)\n    return df\n\ndef clean_data(df):    \n    df = df[['Hugo_Symbol', 'Variant_Classification', 'Tumor_Sample_Barcode']]\n    df = df.dropna()        \n    return df\n\ndef save_data(df, output_path):\n    df.to_csv(output_path, index=False)\n\ndef analyze_data(df):\n    summary = df['Hugo_Symbol'].value_counts().head(10)\n    print(\"Top 10 mutated genes:\")\n    print(summary)\n    # plot the data    \n    fig, ax = plt.subplots()\n    summary.plot(kind='bar', ax=ax)\n    ax.set_xlabel('Gene')\n    ax.set_ylabel('Mutation Count')\n    ax.set_title('Top 10 Mutated Genes')\n    return fig\n\nif __name__ == \"__main__\":\n    # Example usage\n    df = load_data(\"data/raw/pancan_pcawg_2020/data_mutations.txt\")\n    cleaned_df = clean_data(df)\n    save_data(cleaned_df, \"data/processed/cleaned_mutations.csv\")\n    fig = analyze_data(cleaned_df)\n    fig.savefig('results/top10_mutated_genes.png')        \n</code></pre>"},{"location":"good/instructor/03_wednesday/#part-35-starts-at-35-min-takes-10-min-basic-testing","title":"Part 3.5 (starts at 35 min, takes 10 min): Basic Testing","text":"<p>Testing helps catch mistakes and ensures your code works as expected. Let's write a simple test.</p> <p>Create <code>tests/test_analysis.py</code>: <pre><code>import os\nimport sys\nfrom pathlib import Path\nimport pandas as pd\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\nfrom src.python.analysis import load_data, clean_data, save_data, analyze_data\n\ndef create_test_data(tmp_path):\n    df = pd.DataFrame({\n        'Hugo_Symbol': ['TP53', 'BRCA1', 'TP53', 'EGFR'],\n        'Variant_Classification': ['Missense', 'Nonsense', 'Missense', 'Silent'],\n        'Tumor_Sample_Barcode': ['S1', 'S2', 'S3', 'S4']\n    })\n    input_file = tmp_path / 'test_mutations.txt'\n    with open(input_file, 'w') as f:\n        f.write(\"# The cBioPortalFiles\\n\")\n        f.write(\"# Have 2 comment rows before the dataframe\\n\")        \n    # Append the DataFrame below the comments\n    df.to_csv(input_file, sep='\\t', index=False, mode='a')\n    return input_file\n\n\ndef test_pipeline_smoke(tmp_path=Path(\".\")):    \n    # Create test data\n    input_file = create_test_data(tmp_path)        \n    # Run pipeline steps\n    loaded = load_data(input_file)    \n    cleaned = clean_data(loaded)\n    output_file = tmp_path / 'cleaned.csv'\n    save_data(cleaned, output_file)\n    fig = analyze_data(cleaned)\n    plot_file = tmp_path / 'plot.png'\n    fig.savefig(plot_file)\n\n    # Check outputs\n    assert os.path.exists(output_file)\n    out_df = pd.read_csv(output_file)\n    assert not out_df.empty\n    assert set(['Hugo_Symbol', 'Variant_Classification', 'Tumor_Sample_Barcode']).issubset(out_df.columns)\n    assert os.path.exists(plot_file)\n\ntest_pipeline_smoke()\n</code></pre></p> <p>Let's run our test.</p> <pre><code>pytest\n</code></pre>"},{"location":"good/instructor/03_wednesday/#part-36-starts-at-45-min-takes-5-min-ethical-coding-documentation","title":"Part 3.6 (starts at 45 min, takes 5 min): Ethical Coding &amp; Documentation","text":"<p>\"Ethical coding means documenting your work and making it reusable. The Turing Way has a great checklist for code reuse: https://book.the-turing-way.org/reproducible-research/overview/overview-definitions One important aspect documentation, let's add a README to our analysis folder.\"</p>"},{"location":"good/instructor/03_wednesday/#echo-e-analysis-scriptsnthis-folder-contains-python-scripts-for-data-analysis-each-script-is-documented-and-tested-srcpythonreadmemd-cat-srcpythonreadmemd","title":"<pre><code>echo -e \"# Analysis Scripts\\nThis folder contains Python scripts for data analysis. Each script is documented and tested.\" &gt; src/python/README.md\ncat src/python/README.md\n</code></pre>","text":""},{"location":"good/instructor/03_wednesday/#session-wrap-up-homework-starts-at-50-min-takes-5-min","title":"Session Wrap-up &amp; Homework (starts at 50 min, takes 5 min)","text":"<p>Great work today! You set up your project, protected sensitive data, used git in VSCode, created a virtual environment, wrote and tested simple Python code, and documented your work.\"</p>"},{"location":"good/instructor/03_wednesday/#homework-session-consolidation-30-min","title":"Homework (Session Consolidation, ~30 min):","text":"<ul> <li>Review today's steps by:<ul> <li>Creating a simple Python function for data loading or analysis (use your own or example data)</li> <li>Writing a short test to check your function works</li> <li>Adding a brief README or comments to explain your code</li> </ul> </li> <li>Spend a few minutes exploring The Turing Way\u2019s code reuse checklist for ideas on making your code more reusable</li> </ul> <p>See you next session!</p>"},{"location":"good/instructor/04_thursday/","title":"Thursday Session: R for Reproducible Research (Beginner Edition)","text":""},{"location":"good/instructor/04_thursday/#live-coding-script-for-instructors","title":"Live Coding Script for Instructors","text":"<p>Duration: 60 minutes | Format: Participatory live coding Homework: Build a simple, reproducible analysis pipeline in R</p>"},{"location":"good/instructor/04_thursday/#reference","title":"Reference","text":"<p>This session builds on principles from The Turing Way: Code Reuse, a guide to making research code transparent, ethical, and reusable.</p>"},{"location":"good/instructor/04_thursday/#pre-session-setup","title":"Pre-Session Setup","text":"<p>[ASIDE: Open RStudio in your project folder from Monday/Tuesday. Ensure R is installed and available. Have a terminal ready.]</p>"},{"location":"good/instructor/04_thursday/#opening-welcome","title":"Opening &amp; Welcome","text":"<p>Welcome! Today we\u2019ll use R to analyze data in a way that\u2019s reproducible and ethical. We\u2019ll keep things simple and practical, with tips for both beginners and those wanting a refresher.</p>"},{"location":"good/instructor/04_thursday/#part-31-starts-at-0-min-takes-10-min-project-setup-data-privacy","title":"Part 3.1 (starts at 0 min, takes 10 min): Project Setup &amp; Data Privacy","text":"<p>Let's review our project folder structure and talk about data privacy. It's important to keep sensitive data out of version control.</p> <pre><code>ls\ncat .gitignore\n</code></pre> <p>We use a <code>.gitignore</code> file to protect sensitive data and keep our code clean. Let's add some common R exclusions.</p> <pre><code>echo -e \".Rhistory\\n.RData\\n.Rproj.user/\\nrenv/\" &gt;&gt; .gitignore\ncat .gitignore\n</code></pre> <p>The difference between <code>&gt;</code> and <code>&gt;&gt;</code> is that <code>&gt;</code> overwrites the file, while <code>&gt;&gt;</code> appends to it. Always use <code>&gt;&gt;</code> when adding to <code>.gitignore</code>. Or you could ammend in the editor of VSCode too.</p> <p>We also want to make sure we have the folders for R.</p> <pre><code>mkdir -p src/R tests/R\nls\n</code></pre> <p>Open rstudio (use the command line) and then create a new project in the current directory. Now we can see the files we have created. If you have not already initiaised git from the git session do <code>git init</code></p>"},{"location":"good/instructor/04_thursday/#part-32-starts-at-10-min-takes-5-min-setting-up-git-in-rstudio","title":"Part 3.2 (starts at 10 min, takes 5 min): Setting Up Git in RStudio","text":"<p>Now let's make sure our project is tracked with git. RStudio makes this easy.</p> <p>[EDIT: Open the Git tab in RStudio. Show the tracking]</p>"},{"location":"good/instructor/04_thursday/#what-i-type-live-coding","title":"What I Type (Live Coding):","text":"<pre><code>git status\n</code></pre>"},{"location":"good/instructor/04_thursday/#part-33-starts-at-15-min-takes-5-min-creating-an-r-environment","title":"Part 3.3 (starts at 15 min, takes 5 min): Creating an R Environment","text":"<p>A reproducible environment keeps your project dependencies organized. Let's use <code>renv</code> to manage packages.</p> <pre><code># Using the r console in RStudio\ninstall.packages(\"renv\")\nrenv::init()\ninstall.packages(c(\"tidyverse\", \"testthat\"))\nrenv::snapshot()\n</code></pre> <p>Remember to add <code>renv/</code> to your <code>.gitignore</code> so it doesn't get tracked by git.</p> <p>renv::snapshot() saves the current state of your R project's package environment. It records all the packages (and their versions) you have installed into a file called renv.lock. This makes your project reproducible: anyone else (or you in the future) can use renv::restore() to recreate the exact same package environment from that lock file.</p> <p>When you open your project you see something like: <pre><code>- Project '~/good-practice/biomarkers_project' loaded. [renv 1.1.5]\n[Workspace loaded from ~/good-practice/biomarkers_project/.RData]\n</code></pre></p>"},{"location":"good/instructor/04_thursday/#part-34-starts-at-20-min-takes-15-min-writing-simple-reproducible-r-code","title":"Part 3.4 (starts at 20 min, takes 15 min): Writing Simple, Reproducible R Code","text":"<p>Let's download a public dataset so that we have something a little meaningful to work with. We can use bash to do this and download from cBioPortal here: https://www.cbioportal.org/datasets. We will use this set: Acute Myeloid Leukemia (TARGET GDC, 2025) which is 66MB.</p> <pre><code># Using bash\nmkdir -p data/raw\nwget -O data/raw/aml_tcga_gdc.tar.gz https://cbioportal-datahub.s3.amazonaws.com/aml_tcga_gdc.tar.gz\ntar -xzvf data/raw/aml_tcga_gdc.tar.gz -C data/raw\n</code></pre> <p>This has extracted a fair amount of data. We won't use all of it but we can use some for our examples, let's use the file: <code>data/raw/aml_tcga_gdc/data_mutatations.txt</code>. You can see now how important it was that we added all the files in raw to our .gitognore as I don't need to worry that I might accidentally commit them all to the GitLab cloud.</p> <p>Let's write a simple function to load data. Clear function names and documentation help others understand your code. Create <code>src/R/analysis.R</code>:</p> <p>MOVE TO VIDEO 2</p> <pre><code>#!/usr/bin/env Rscript\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nload_data &lt;- function(filepath) {\n  df &lt;- read_tsv(filepath, skip = 2)\n  return(df)\n}\n\nclean_data &lt;- function(df) {\n  df &lt;- df %&gt;%\n    select(Hugo_Symbol, Variant_Classification, Tumor_Sample_Barcode) %&gt;%\n    na.omit()\n  return(df)\n}\n\nsave_data &lt;- function(df, output_path) {\n  write_csv(df, output_path)\n}\n\nanalyze_data &lt;- function(df) {\n  summary &lt;- df %&gt;%\n    count(Hugo_Symbol, sort = TRUE) %&gt;%\n    head(10)\n  print(\"Top 10 mutated genes:\")\n  print(summary)\n  p &lt;- ggplot(summary, aes(x = reorder(Hugo_Symbol, -n), y = n)) +\n    geom_bar(stat = \"identity\") +\n    xlab(\"Gene\") +\n    ylab(\"Mutation Count\") +\n    ggtitle(\"Top 10 Mutated Genes\") +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n  return(p)\n}\n\n# Example usage\n# df &lt;- load_data(\"data/raw/aml_tcga_gdc/data_mutations.txt\")\n# cleaned_df &lt;- clean_data(df)\n# save_data(cleaned_df, \"data/processed/cleaned_mutations.csv\")\n# p &lt;- analyze_data(cleaned_df)\n# ggsave(\"results/top10_mutated_genes.png\", plot = p, width = 8, height = 5)\n</code></pre> <p>MOVE to VIDEO 3</p> <p>If we uncomment out the Exaple usage section it will run through a test</p>"},{"location":"good/instructor/04_thursday/#part-35-starts-at-35-min-takes-10-min-basic-testing","title":"Part 3.5 (starts at 35 min, takes 10 min): Basic Testing","text":"<p>Testing helps catch mistakes and ensures your code works as expected. Let's write a simple test.</p> <p>Create <code>tests/R/test_analysis.R</code>: <pre><code>library(testthat)\nsource(\"../../src/R/analysis.R\")\n\ntest_that(\"pipeline smoke test\", {\n  df &lt;- data.frame(\n    Hugo_Symbol = c(\"TP53\", \"BRCA1\", \"TP53\", \"EGFR\"),\n    Variant_Classification = c(\"Missense\", \"Nonsense\", \"Missense\", \"Silent\"),\n    Tumor_Sample_Barcode = c(\"S1\", \"S2\", \"S3\", \"S4\")\n  )\n  cleaned &lt;- clean_data(df)\n  expect_true(nrow(cleaned) &gt; 0)\n  expect_true(all(c(\"Hugo_Symbol\", \"Variant_Classification\", \"Tumor_Sample_Barcode\") %in% colnames(cleaned)))\n})\n</code></pre></p> <p>Let's run our test.</p> <pre><code># In the R console\ntestthat::test_file(\"tests/R/test_analysis.R\")\n</code></pre>"},{"location":"good/instructor/04_thursday/#part-36-starts-at-45-min-takes-5-min-ethical-coding-documentation","title":"Part 3.6 (starts at 45 min, takes 5 min): Ethical Coding &amp; Documentation","text":"<p>Ethical coding means documenting your work and making it reusable. The Turing Way has a great checklist for code reuse: https://book.the-turing-way.org/reproducible-research/overview/overview-definitions One important aspect is documentation. Let's add a README to our analysis folder.</p>"},{"location":"good/instructor/04_thursday/#what-i-type-live-coding_1","title":"What I Type (Live Coding):","text":""},{"location":"good/instructor/04_thursday/#echo-e-analysis-scriptsnthis-folder-contains-r-scripts-for-data-analysis-each-script-is-documented-and-tested-srcrreadmemd-cat-srcrreadmemd","title":"<pre><code>echo -e \"# Analysis Scripts\\nThis folder contains R scripts for data analysis. Each script is documented and tested.\" &gt; src/R/README.md\ncat src/R/README.md\n</code></pre>","text":""},{"location":"good/instructor/04_thursday/#session-wrap-up-homework-starts-at-50-min-takes-5-min","title":"Session Wrap-up &amp; Homework (starts at 50 min, takes 5 min)","text":"<p>Great work today! You set up your project, protected sensitive data, used git in RStudio, created a reproducible environment, wrote and tested simple R code, and documented your work.</p>"},{"location":"good/instructor/04_thursday/#homework-session-consolidation-30-min","title":"Homework (Session Consolidation, ~30 min):","text":"<ul> <li>Review today's steps by:<ul> <li>Creating a simple R function for data loading or analysis (use your own or example data)</li> <li>Writing a short test to check your function works</li> <li>Adding a brief README or comments to explain your code</li> </ul> </li> <li>Spend a few minutes exploring The Turing Way\u2019s code reuse checklist for ideas on making your code more reusable</li> </ul> <p>See you next session!</p>"},{"location":"good/instructor/05_friday/","title":"Friday Live Coding Script: Good-Practices with Conda and Docker","text":"<p>instructor home</p>"},{"location":"good/instructor/05_friday/#friday-session-timings-instructor-guide-revised","title":"Friday Session Timings (Instructor Guide) \u2014 Revised","text":"Part Section(s) Covered Suggested Time Running Time 1 Opening, Welcome &amp; Why Use Conda and Docker 10 min 10 2 Creating and Using Conda Environments (Python &amp; R) 15 min 25 3 Introduction to Docker &amp; Writing a Dockerfile 10 min 35 4 Building and Running Python &amp; R Scripts in Docker 20 min 55 5 Wrap-up, Best Practices &amp; Homework 5 min 60"},{"location":"good/instructor/05_friday/#part-1-opening-welcome-why-use-conda-and-docker","title":"Part 1: Opening, Welcome &amp; Why Use Conda and Docker","text":"<p>Welcome to our final session! Today, we\u2019ll learn how to use Conda and Docker to make our research environments reproducible and portable. This is essential for sharing your work and ensuring others (and future you!) can run your code.</p> <ul> <li>Conda helps you manage packages and environments for Python, R, and more.</li> <li>Docker lets you package your code and environment into a container that runs anywhere.</li> </ul>"},{"location":"good/instructor/05_friday/#part-2-creating-and-using-conda-environments-python-r","title":"Part 2: Creating and Using Conda Environments (Python &amp; R)","text":"<p>Let\u2019s start by creating Conda environments for both Python and R, matching the packages we\u2019ve used this week.</p>"},{"location":"good/instructor/05_friday/#python-environment","title":"Python Environment","text":"<pre><code># Create a new conda environment for Python\nconda create -n good-python python=3.11 pandas matplotlib pytest -y\nconda activate good-python\n\n# Check installed packages\nconda list\n\n# Run your Python script\npython src/python/analysis.py\n</code></pre>"},{"location":"good/instructor/05_friday/#r-environment","title":"R Environment","text":"<pre><code># Create a new conda environment for R\nconda create -n good-r r-base=4.3 r-tidyverse r-ggplot2 r-testthat -y\nconda activate good-r\n\n# Start R and run your script\nRscript src/R/analysis.R\n</code></pre> <p>Tip: You can export your environment for sharing: <pre><code>conda env export &gt; environment.yml\nconda env export --no-build &gt; environment-no.yml\n</code></pre></p>"},{"location":"good/instructor/05_friday/#part-3-introduction-to-docker-writing-a-dockerfile","title":"Part 3: Introduction to Docker &amp; Writing a Dockerfile","text":"<p>Docker lets you create a container with everything your code needs. Let\u2019s write a simple Dockerfile for both Python and R.</p>"},{"location":"good/instructor/05_friday/#python-dockerfile-dockerdockerfilepython","title":"Python Dockerfile (<code>docker/Dockerfile.python</code>)","text":"<pre><code># ---------- Python dockerfile --------------------------------\n# BUILD IT:     docker build -f docker/Dockerfile.python -t good-python .\n# CHECK IT:     docker run -it good-python /bin/bash\n# RUN IT:       docker run -v ./data:/app/data -v ./results:/app/results good-python\n# -------------------------------------------------------------\nFROM python:3.13-slim\nWORKDIR /app\nRUN pip install pandas matplotlib pytest\nCOPY src/python/analysis.py ./analysis.py\nCMD [\"python\", \"analysis.py\"]\n</code></pre>"},{"location":"good/instructor/05_friday/#r-dockerfile-dockerdockerfilerscript","title":"R Dockerfile (<code>docker/Dockerfile.rscript</code>)","text":"<pre><code># filepath: Dockerfile.rscript\nFROM rocker/r-base:4.3.1\n\nWORKDIR /app\n\nCOPY src/R/analysis.R ./analysis.R\nCOPY data/raw ./data/raw\n\nRUN R -e \"install.packages(c('tidyverse', 'ggplot2', 'testthat'), repos='https://cloud.r-project.org')\"\n\nCMD [\"Rscript\", \"analysis.R\"]\n</code></pre>"},{"location":"good/instructor/05_friday/#part-4-building-and-running-python-r-scripts-in-docker","title":"Part 4: Building and Running Python &amp; R Scripts in Docker","text":"<p>Let\u2019s build and run our containers!</p>"},{"location":"good/instructor/05_friday/#python","title":"Python","text":"<pre><code># Build the Python Docker image\ndocker build -f docker/Dockerfile.python -t good-python .\n# Look inside the docker image and navigate with bash\ndocker run -it good-python /bin/bash\n# Run the Python container\ndocker run --rm -v $(pwd)/data:/app/data -v $(pwd)/results:/app/results good-python\n</code></pre>"},{"location":"good/instructor/05_friday/#r","title":"R","text":"<pre><code># Build the R Docker image\ndocker build -f docker/Dockerfile.r -t good-r .\n\n# Run the R container\ndocker run --rm -v $(pwd)/data:/app/data -v $(pwd)/results:/app/results good-r\n</code></pre> <p>Tip: The <code>-v</code> flag mounts your local data and results folders into the container, so outputs are saved outside the container.</p>"},{"location":"good/instructor/05_friday/#conda-dockerfile-dockerdockerfileconda","title":"Conda Dockerfile (<code>docker/Dockerfile.conda</code>)","text":"<pre><code># filepath: Dockerfile.conda\nFROM continuumio/miniconda3:latest\n\nWORKDIR /app\n\n# Copy your environment file and scripts\nCOPY environment.yml .\nCOPY src/python/analysis.py ./analysis.py\nCOPY src/R/analysis.R ./analysis.R\nCOPY data/raw ./data/raw\n\n# Create the conda environment\nRUN conda env create -f environment.yml\n\n# Ensure conda environment is activated by default\nSHELL [\"conda\", \"run\", \"-n\", \"good-env\", \"/bin/bash\", \"-c\"]\n\n# Set entrypoint to run either script (pass as argument)\nENTRYPOINT [\"conda\", \"run\", \"-n\", \"good-env\"]\n\n# Default command (can be overridden)\nCMD [\"python\", \"analysis.py\"]\n</code></pre> <pre><code># Build the Conda Docker image\ndocker build -f docker/Dockerfile.conda -t good-conda .\n# Look inside the docker image and navigate with bash\ndocker run -it good-python /bin/bash\n# Run the python script\ndocker run --rm -v $(pwd)/data:/app/data -v $(pwd)/results:/app/results good-conda python analysis.py\n# Run the R script\ndocker run --rm -v $(pwd)/data:/app/data -v $(pwd)/results:/app/results good-conda Rscript analysis.R\n</code></pre>"},{"location":"good/instructor/05_friday/#part-5-wrap-up-best-practices-homework","title":"Part 5: Wrap-up, Best Practices &amp; Homework","text":"<ul> <li> <p>Best Practices:</p> <ul> <li>Always use environment files (<code>environment.yml</code>, <code>Dockerfile</code>) for reproducibility.</li> <li>Document your dependencies and how to run your code.</li> <li>Use containers for sharing and deploying your research.</li> </ul> </li> <li> <p>Homework:</p> <ul> <li>Try building and running your own Docker container for a different script or project.</li> <li>Share your <code>environment.yml</code> or <code>Dockerfile</code> with a collaborator and see if they can reproduce your results.</li> </ul> </li> </ul>"},{"location":"good/instructor/05_friday/#part-2-building-a-singularity-image-from-a-dockerfile","title":"Part 2: Building a Singularity Image from a Dockerfile","text":"<p>Let\u2019s convert our Docker image to a Singularity image (<code>.sif</code> file).</p>"},{"location":"good/instructor/05_friday/#1-install-singularity-if-needed-on-your-local-machine","title":"1. Install Singularity (if needed, on your local machine)","text":"<pre><code># On Ubuntu (if you have sudo)\nsudo apt-get update\nsudo apt-get install singularity-container\n# Or use Apptainer (new name)\nsudo apt-get install apptainer\n</code></pre>"},{"location":"good/instructor/05_friday/#2-build-the-sif-file-from-your-dockerfile","title":"2. Build the SIF file from your Dockerfile","text":"<pre><code># Build the Docker image first (if not already done)\ndocker build -f Dockerfile.conda -t good-conda .\n\n# Convert the Docker image to a Singularity SIF file\nsingularity build good-conda.sif docker-daemon://good-conda:latest\n</code></pre> <p>Note: You may need root/admin privileges to build the SIF file.</p>"},{"location":"good/instructor/05_friday/#part-3-transferring-the-sif-file-to-the-hpc","title":"Part 3: Transferring the SIF File to the HPC","text":"<p>Now, let\u2019s transfer the <code>.sif</code> file to Alma using <code>scp</code> or <code>rsync</code>.</p> <pre><code># From your local machine\nscp good-conda.sif &lt;username&gt;@alma.icr.ac.uk:/data/your_folder/\n# Or using rsync\nrsync -av good-conda.sif &lt;username&gt;@alma.icr.ac.uk:/data/your_folder/\n</code></pre> <p>Log in to Alma and check the file is there:</p> <pre><code>ssh &lt;username&gt;@alma.icr.ac.uk\nls /data/your_folder/good-conda.sif\n</code></pre>"},{"location":"good/instructor/05_friday/#part-4-running-python-r-scripts-in-singularity-on-alma","title":"Part 4: Running Python &amp; R Scripts in Singularity on Alma","text":"<p>Let\u2019s run our code inside the container on the HPC.</p> <pre><code># Load Singularity module if needed\nmodule load singularity\n\n# Run the Python script\nsingularity exec --bind /data/your_folder/data:/app/data,/data/your_folder/results:/app/results good-conda.sif python analysis.py\n\n# Run the R script\nsingularity exec --bind /data/your_folder/data:/app/data,/data/your_folder/results:/app/results good-conda.sif Rscript analysis.R\n</code></pre> <p>Tip: The <code>--bind</code> option mounts your data and results folders inside the container.</p> <p>For batch jobs: Create a simple SLURM script (e.g., <code>run_container.slurm</code>):</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=run_container\n#SBATCH --output=container_output.txt\n#SBATCH --time=01:00:00\n#SBATCH --cpus-per-task=2\n#SBATCH --mem=4G\n\nmodule load singularity\nsingularity exec --bind /data/your_folder/data:/app/data,/data/your_folder/results:/app/results good-conda.sif python analysis.py\n</code></pre> <p>Submit with: <pre><code>sbatch run_container.slurm\n</code></pre></p>"},{"location":"good/instructor/05_friday/#part-5-wrap-up-best-practices-homework_1","title":"Part 5: Wrap-up, Best Practices &amp; Homework","text":"<ul> <li> <p>Best Practices:</p> <ul> <li>Use Singularity for reproducible, portable research on HPC.</li> <li>Always test your container locally before transferring to HPC.</li> <li>Document your workflow for others to follow.</li> </ul> </li> <li> <p>Homework:</p> <ul> <li>Try building and running a Singularity container for a different project.</li> <li>Share your <code>.sif</code> file and workflow with a collaborator.</li> </ul> </li> </ul>"},{"location":"good/instructor/05_friday/#session-cheat-sheet-singularity-on-hpc","title":"Session Cheat Sheet: Singularity on HPC","text":"<pre><code># Build Docker image\ndocker build -f Dockerfile.conda -t good-conda .\nsingularity build good-conda.sif docker-daemon://good-conda:latest\n#or \ndocker save good-conda:latest -o good-conda.tar\nsingularity build good-conda.sif docker-archive://good-conda.tar\n\n# Use files to transfer to scratch and copy data\n## Run the Python script\nsingularity exec --bind data:/app/data,results:/app/results good-conda.sif bash -c \"source /opt/conda/etc/profile.d/conda.sh &amp;&amp; conda run -n good-env python /app/analysis.py\"\n\n## Run the R script\nsingularity exec --bind data:/app/data,results:/app/results good-conda.sif bash -c \"source /opt/conda/etc/profile.d/conda.sh &amp;&amp; conda run -n good-env Rscript /app/analysis.R\"\n</code></pre> <p>Congratulations on completing the course!</p>"},{"location":"good/instructor/06_Saturday/","title":"Final Session: Running Reproducible Research with Singularity on HPC","text":"<p>instructor home</p>"},{"location":"good/instructor/06_Saturday/#final-session-timings-instructor-guide-revised","title":"Final Session Timings (Instructor Guide) \u2014 Revised","text":"Part Section(s) Covered Suggested Time Running Time 1 Opening, Welcome &amp; Why Use Singularity on HPC 10 min 10 2 Building a Singularity Image from a Dockerfile 15 min 25 3 Transferring the SIF File to the HPC 10 min 35 4 Running Python &amp; R Scripts in Singularity on Alma 20 min 55 5 Wrap-up, Best Practices &amp; Homework 5 min 60"},{"location":"good/instructor/06_Saturday/#part-1-opening-welcome-why-use-singularity-on-hpc","title":"Part 1: Opening, Welcome &amp; Why Use Singularity on HPC","text":"<p>Welcome to our final session! Today, we\u2019ll see how to use Singularity (now called Apptainer) to run your containerized research code on the Alma HPC. Singularity is designed for HPC environments and works well with Docker images.</p> <ul> <li>Singularity runs containers securely on shared systems like HPC clusters.</li> <li>You can convert your Docker images to Singularity images and run them on Alma.</li> </ul>"},{"location":"good/instructor/06_Saturday/#part-2-building-a-singularity-image-from-a-dockerfile","title":"Part 2: Building a Singularity Image from a Dockerfile","text":"<p>Let\u2019s convert our Docker image to a Singularity image (<code>.sif</code> file).</p>"},{"location":"good/instructor/06_Saturday/#1-install-singularity-if-needed-on-your-local-machine","title":"1. Install Singularity (if needed, on your local machine)","text":"<pre><code># On Ubuntu (if you have sudo)\nsudo apt-get update\nsudo apt-get install singularity-container\n# Or use Apptainer (new name)\nsudo apt-get install apptainer\n</code></pre>"},{"location":"good/instructor/06_Saturday/#2-build-the-sif-file-from-your-dockerfile","title":"2. Build the SIF file from your Dockerfile","text":"<pre><code># Build the Docker image first (if not already done)\ndocker build -f Dockerfile.conda -t good-conda .\n\n# Convert the Docker image to a Singularity SIF file\nsingularity build good-conda.sif docker-daemon://good-conda:latest\n</code></pre> <p>Note: You may need root/admin privileges to build the SIF file.</p>"},{"location":"good/instructor/06_Saturday/#part-3-transferring-the-sif-file-to-the-hpc","title":"Part 3: Transferring the SIF File to the HPC","text":"<p>Now, let\u2019s transfer the <code>.sif</code> file to Alma using <code>scp</code> or <code>rsync</code>.</p> <pre><code># From your local machine\nscp good-conda.sif &lt;username&gt;@alma.icr.ac.uk:/data/your_folder/\n# Or using rsync\nrsync -av good-conda.sif &lt;username&gt;@alma.icr.ac.uk:/data/your_folder/\n</code></pre> <p>Log in to Alma and check the file is there:</p> <pre><code>ssh &lt;username&gt;@alma.icr.ac.uk\nls /data/your_folder/good-conda.sif\n</code></pre>"},{"location":"good/instructor/06_Saturday/#part-4-running-python-r-scripts-in-singularity-on-alma","title":"Part 4: Running Python &amp; R Scripts in Singularity on Alma","text":"<p>Let\u2019s run our code inside the container on the HPC.</p> <pre><code># Load Singularity module if needed\nmodule load singularity\n\n# Run the Python script\nsingularity exec --bind /data/your_folder/data:/app/data,/data/your_folder/results:/app/results good-conda.sif python analysis.py\n\n# Run the R script\nsingularity exec --bind /data/your_folder/data:/app/data,/data/your_folder/results:/app/results good-conda.sif Rscript analysis.R\n</code></pre> <p>Tip: The <code>--bind</code> option mounts your data and results folders inside the container.</p> <p>For batch jobs: Create a simple SLURM script (e.g., <code>run_container.slurm</code>):</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=run_container\n#SBATCH --output=container_output.txt\n#SBATCH --time=01:00:00\n#SBATCH --cpus-per-task=2\n#SBATCH --mem=4G\n\nmodule load singularity\nsingularity exec --bind /data/your_folder/data:/app/data,/data/your_folder/results:/app/results good-conda.sif python analysis.py\n</code></pre> <p>Submit with: <pre><code>sbatch run_container.slurm\n</code></pre></p>"},{"location":"good/instructor/06_Saturday/#part-5-wrap-up-best-practices-homework","title":"Part 5: Wrap-up, Best Practices &amp; Homework","text":"<ul> <li> <p>Best Practices:</p> <ul> <li>Use Singularity for reproducible, portable research on HPC.</li> <li>Always test your container locally before transferring to HPC.</li> <li>Document your workflow for others to follow.</li> </ul> </li> <li> <p>Homework:</p> <ul> <li>Try building and running a Singularity container for a different project.</li> <li>Share your <code>.sif</code> file and workflow with a collaborator.</li> </ul> </li> </ul>"},{"location":"good/instructor/06_Saturday/#session-cheat-sheet-singularity-on-hpc","title":"Session Cheat Sheet: Singularity on HPC","text":"<pre><code># Build Docker image\ndocker build -f Dockerfile.conda -t good-conda .\n\n# Convert Docker image to Singularity SIF\nsingularity build good-conda.sif docker-daemon://good-conda:latest\n\n# Transfer SIF to HPC\nscp good-conda.sif &lt;username&gt;@alma.icr.ac.uk:/data/your_folder/\n\n# On Alma: Run Python\nsingularity exec --bind /data/your_folder/data:/app/data,/data/your_folder/results:/app/results good-conda.sif python analysis.py\n\n# On Alma: Run R\nsingularity exec --bind /data/your_folder/data:/app/data,/data/your_folder/results:/app/results good-conda.sif Rscript analysis.R\n\n# Submit as a batch job\nsbatch run_container.slurm\n</code></pre> <p>Congratulations on completing the course!</p>"},{"location":"good/instructor/overview/","title":"Instructor page: Good Practice Webinar","text":"Day Topic Live Session Highlights Homework Focus Monday Command Line &amp; VSCode Foundations Project organization, command line, VSCode setup Create standardized project structure Tuesday Git &amp; Collaboration Workflows Git basics, collaboration, merge conflicts, code review Implement version control workflow Wednesday Python Development in VSCode Testing, ethics, bias detection, analysis pipeline Build tested, ethical Python analysis pipeline Thursday R Development in RStudio Statistical testing, reporting, Python-R integration Create R workflow with validation and reporting Friday Computational Reproducibility Conda/Docker environments, sharing, sustainability Complete integrated reproducible research pipeline"},{"location":"resources/cicd/","title":"Continuous Integration and Continuous Deployment","text":""},{"location":"resources/cicd/#introduction","title":"Introduction","text":"<p>Projects should have built in to them a form of continuous integration to automate testing and deployment. This is a key part of the software development process and is essential for ensuring that code is of high quality and is deployed quickly and efficiently. It is of particular importance in the scientific community where reproducibility is key.</p>"},{"location":"resources/cicd/#what-is-cicd","title":"What is CI/CD?","text":"<p>Continuous Integration (CI) is the practice of automating the integration of code changes from contributors into a single software project. It includes ensuring that people don;t break each other's changes, and that the key requirements are not broken by changes. This is done by automatically building and testing the code whenever a change is made, and providing feedback to the developers.</p> <p>Continuous Deployment (CD) is the practice of automatically deploying code changes to a production environment whenever they pass the automated tests. This is done to ensure that code changes are deployed quickly and efficiently, and to reduce the risk of errors in the deployment process. This can be automated to a greater or lesser extent depending on the requirements of the project - some projects may require manual approval before deployment, while others may deploy automatically.</p>"},{"location":"resources/cicd/#why-use-cicd","title":"Why use CI/CD?","text":"<p>There are several benefits to using CI/CD in software development:</p> <ul> <li>Faster feedback: CI/CD provides immediate feedback to developers on the quality of their code, allowing them to fix issues quickly and efficiently.</li> <li>Reduced risk: CI/CD automates the testing and deployment process, reducing the risk of human error and ensuring that code changes are deployed consistently.</li> <li>Faster deployment: CI/CD automates the deployment process, allowing code changes to be deployed quickly and efficiently.</li> <li>Improved quality: CI/CD enforces best practices in software development, ensuring that code changes are of high quality and meet the project's standards.</li> <li>Definition of \"right\" - by using tests to define the requirements of the code you have a definition of the project's requirements that can be tested against.</li> <li>Reproducibility - by having a defined set of tests that are run on every change, you can ensure that the code is reproducible and that the tests are run on every change.</li> </ul>"},{"location":"resources/cicd/#how-to-use-cicd-at-the-icr","title":"How to use CI/CD at the ICR","text":"<p>At the ICR we use github actions to automate the CI/CD process. This allows us to define workflows that automate the building, testing, and deployment of code changes. For the test framework for a given language click on the langaue Good Practices link in the left hand menu. </p>"},{"location":"resources/cicd/#github-actions","title":"Github Actions","text":"<p>Github Actions is a feature of Github that allows you to automate the building, testing, and deployment of code changes. It is a powerful tool that can be used to define workflows that automate the entire software development process.</p> <p>For docs on github actions see the github actions documentation.</p> <p>For ICR help please contact the schelpdesk@icr.ac.uk. An example of a project with CICD is SPORANO.  This has a public website SOPRANO website and a public github repo where you can see in the workflows directory there tests, linting, documentation and deployment (to docker) actions.</p>"},{"location":"resources/hpc/","title":"Using Alma's HPC system","text":"<p>New user's guide on nexus</p>"},{"location":"resources/packaging/","title":"Packaging Code for re-usability","text":""},{"location":"resources/packaging/#introduction","title":"Introduction","text":"<p>Packaging is the process of bundling your code into a distributable format that can be installed and used by others. Packaging your code makes it easier for others to use and contribute to your project, and helps ensure that your code is reproducible and maintainable. </p> <p>The appropriate package will depend on how you want the code to be used, but equally the available packages and best practices could influence how you design your code.</p>"},{"location":"resources/packaging/#libraries","title":"Libraries","text":"<p>In both R and python libraries can be created to package code. In python these packages can be installed with <code>pip install</code> and in R with <code>install.packages</code>.</p>"},{"location":"resources/packaging/#containers","title":"Containers","text":"<p>Containers are a way of packaging code and its dependencies into a single unit that can be run in any environment. Containers are lightweight, portable, and can be run on any platform that supports the container runtime. Some popular container runtimes include Docker and Singularity.</p>"},{"location":"resources/packaging/#web-applications","title":"Web Applications","text":"<p>Web applications can be packaged as Docker containers, which can be deployed to a cloud platform such as AWS, Google Cloud, or Azure. This allows you to easily scale your application, and ensures that it runs consistently across different environments.</p>"},{"location":"resources/packaging/#packaging-at-the-icr","title":"Packaging at the ICR","text":"<p>At the ICR we use a combination of Python packages and Docker containers to package our code. Python packages are used for libraries and command-line tools, while Docker containers are used for web applications and services. We also use Github Actions to automate the packaging and deployment process, which ensures that our code is packaged consistently and reproducibly.</p> <p>We have developed a model of 3-tier packaging for our code that enables users to go from minimum-requirements to expert HPC. For this we use: - A webapp hosted at the ICR - light weight for explaration only - A docker container that can be run on any machine for heavier use of the application - A docker command line tool of the same code for more intensive local use - That same command line util can be run though singularity on Alma</p> <p>Please contact schelpdesk@icr.ac.uk if we can help with any aspect of packaging your software.</p> <p>An example of a project with this multi-tier packaging is pisca-box.</p> <ul> <li>Public web application Pisca-box website</li> <li>Docker container for web app Pisca-box docker container</li> <li>Docker container for command line tool Pisca-run docker container</li> </ul>"},{"location":"resources/python/","title":"Python Good Practises","text":""},{"location":"resources/python/#introduction","title":"Introduction","text":"<p>Python is a powerful and flexible programming language that is widely used in scientific software development. It is known for its simplicity and readability, which makes it an excellent choice for beginners and experienced programmers alike. This document outlines some good practices for developing scientific software in Python.</p>"},{"location":"resources/python/#style","title":"Style","text":"<p>Python has a well-defined coding style that is outlined in PEP 8. Following this style guide will make your code more readable and maintainable, and will help you avoid common pitfalls in Python programming.</p> <p>Some key points from PEP 8 include: - Use 4 spaces for indentation - Limit lines to 79 characters - Use blank lines to separate functions and classes - Use descriptive variable and function names - Use comments to explain complex code</p> <p>Additionally, use type hints</p>"},{"location":"resources/python/#documentation","title":"Documentation","text":"<p>Documentation is an essential part of software development, as it helps other developers understand your code and how to use it. Python has a built-in documentation system called docstrings, which allows you to write documentation directly in your code.</p> <p>Some key points for writing good documentation include: - Use docstrings to document functions, classes, and modules - Use descriptive names for functions and variables - Write clear and concise comments</p>"},{"location":"resources/python/#testing","title":"Testing","text":"<p>Testing is an important part of software development, as it helps you ensure that your code is working correctly and that it continues to work as you make changes. For python we use pytest and have it built into the continuous integration pipelines - see CI/CD</p> <p>An important concept in testing is that of the tests for scientific requirements. These are tests that define the project's scientific requirements and key algorithms and form the basis of proof of the scientific software.</p> <p>Some key points for writing good tests include: - Write tests for scientific proof of the code - Write tests for all functions and classes - Test edge cases and corner cases - Use descriptive test names - Build tests into the continuous integration pipeline</p>"},{"location":"resources/python/#packaging","title":"Packaging","text":"<p>Packaging is the process of bundling your code into a distributable format that can be installed and used by others See packaging and deploying.</p>"},{"location":"resources/version/","title":"Version Control","text":""},{"location":"resources/version/#summary","title":"Summary","text":"<p>Version control is a key part of software development, as it allows you to track changes to your code and collaborate with other developers. It also enables reproducibility and ensures that you can revert to previous versions of your code if needed. Github enables the creation of </p>"},{"location":"resources/version/#at-the-icr","title":"At the ICR","text":"<ul> <li>an internal gitlab server that you can use to store your code. This is accessible at gitlab.icr.ac.uk (only available internally or on the VPN).</li> <li>A github enterprise account that you can use to store your code. This is accessible at ICR github. To become a member of this github please send a request to schelpdesk@icr.ac.uk.</li> </ul>"},{"location":"resources/version/#key-points","title":"Key points","text":"<ul> <li>Use descriptive commit messages</li> <li>Create branches for new features or bug fixes</li> <li>Merge changes regularly to avoid conflicts</li> <li>Use pull requests for code reviews</li> </ul>"},{"location":"resources/version/#doi-with-zenodo","title":"DOI with Zenodo","text":"<ul> <li>Zenodo is a service that allows you to create a DOI for your code, which can be used to cite your code in publications. You can create a DOI for your code by creating a release on Github and then linking your Github repository to Zenodo.</li> </ul> <p>Please ask for help at any point! RSE Group</p>"},{"location":"resources/version/#link-to-zenodo","title":"Link to zenodo","text":"<ol> <li>Link the github account you use for ICR with zenodo: Log on to zenodo and choose to sign in with github</li> <li>Make sure you grant access to the Institute of Cancer Research institution when you grant access via github</li> <li>You can chose to link to your orcid or your github account</li> <li>You will get an email to confirm your account</li> </ol>"},{"location":"resources/version/#prepare-a-release","title":"Prepare a release","text":"<ol> <li>Edit the README.md of the repo with your service details.</li> <li>Look at the RSE Group as a guide or contact the RSE Group for assistance.</li> <li>Make a release by going to the release pages on the right of github, or from zenodo's github page. When you navigate to the repo page in zenodo take care to only give access to YOUR repo as you make see a list of institution repos</li> </ol>"},{"location":"resources/version/#find-your-badge","title":"Find your badge","text":"<ol> <li>Back on the Zenodo page a badge is automatically created, with a link to a zip of the code, like </li> </ol> <p>However, be aware that this is a link to the latest release, so this will change with every release. It may be more appropriate to use the explicit most recent version DOI link so that if anyone uses it it refers to the exact version of the services at that time. To do this, find the release specific DOI button and click it. </p> <p>Take a copy of the DOI link from this badge for the pinned version (choose link, markdowen etc, I am using markdown in this example).</p> <p>Finally, the dynamic DOI for this service is this:  <code>[![DOI](https://zenodo.org/badge/755024489.svg)](https://zenodo.org/doi/10.5281/zenodo.10638989)</code></p> <p>But at the time of writing the latest is v1.0.5:   <code>[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10684363.svg)](https://doi.org/10.5281/zenodo.10684363)</code></p> <p>The number will be the same while v1.0.5 is the most recent release.</p>"},{"location":"vibe/ai/","title":"Using AI in Coding","text":"<p>AI is a powerful tool that can be used to help you write code. It can help you write code faster, find bugs, and even generate code for you. In this article, we'll explore some of the ways you can use AI in your coding workflow.</p>"},{"location":"vibe/ai/#github-copilot","title":"Github copilot","text":"<p>This is built into VSCode but requires a license. You can acquire a license as ICR staff though the github teachers and researchers academic program.</p> <p>Information on copilot with vscode</p>"},{"location":"vibe/overview/","title":"Vibe-Coding with VSCode Good Practice","text":"<p>Coming soon in February 2026</p>"}]}